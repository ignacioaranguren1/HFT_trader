{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8872fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import keras_tuner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e498df4",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c6a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r'/Users/ignacioaranguren/QR_assignment/'\n",
    "os.chdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e60f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Matching Time', 'Receiving Time', 'Symbol']\n",
    "for i in range(1,11):\n",
    "    columns += [f'BID_PRICE{i}', f'BID_QTY_{i}', f'ASK_PRICE_{i}', f'ASK_QTY_{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013197c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp = pd.read_csv(f'data/exchange1_20210519.csv', names=columns).set_index('Matching Time').append(pd.read_csv(f'data/exchange1_20210520.csv', names=columns).set_index('Matching Time'))\n",
    "df_test_tmp = pd.read_csv(f'data/exchange1_20210521.csv', names=columns).set_index('Matching Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e34bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train_tmp[df_train_tmp.columns[2:]])\n",
    "df_train_tmp[df_train_tmp.columns[2:]] = scaler.fit_transform(df_train_tmp[df_train_tmp.columns[2:]])\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_test_tmp[df_test_tmp.columns[2:]])\n",
    "df_test_tmp[df_test_tmp.columns[2:]] = scaler.fit_transform(df_test_tmp[df_test_tmp.columns[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66efddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp['MID_PRICE'] = (df_train_tmp['BID_PRICE1'] + df_train_tmp['ASK_PRICE_1']) / 2\n",
    "df_test_tmp['MID_PRICE'] = (df_test_tmp['BID_PRICE1'] + df_test_tmp['ASK_PRICE_1']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a14f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_price_trend(df, k, alpha):\n",
    "    # Contiguous mid values may be noisy. We need to smooth them by calculating the mean to infere the price trend\n",
    "    trend = []\n",
    "    for i in tqdm(range(k//2, len(df['MID_PRICE']) - k//2)):\n",
    "        prev_k_mid_prices = df.iloc[i - k//2: i, -1].mean()\n",
    "        next_k_mid_prices = df.iloc[i: i + k//2, -1].mean()\n",
    "        if prev_k_mid_prices < next_k_mid_prices * (1 + alpha):\n",
    "            trend += [1]\n",
    "        elif prev_k_mid_prices > next_k_mid_prices * (1 - alpha):\n",
    "            trend += [-1]\n",
    "        else:\n",
    "            trend += [0]\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbbb376",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_HORIZON = 20\n",
    "ALPHA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927a08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4523864/4523864 [18:55<00:00, 3984.91it/s]\n"
     ]
    }
   ],
   "source": [
    "trend_train = mid_price_trend(df_train_tmp, K_HORIZON, ALPHA)\n",
    "df_train_tmp['TREND_MID_PRICE'] = pd.Series(trend_train, index=df_train_tmp.index[K_HORIZON//2:-K_HORIZON//2]) \n",
    "df_train_tmp = df_train_tmp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b906b61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2403150/2403150 [10:12<00:00, 3926.26it/s]\n"
     ]
    }
   ],
   "source": [
    "trend_test = mid_price_trend(df_test_tmp, K_HORIZON, ALPHA)\n",
    "df_test_tmp['TREND_MID_PRICE'] = pd.Series(data=trend_test, index=df_test_tmp.index[K_HORIZON//2:-K_HORIZON//2]) \n",
    "df_test_tmp = df_test_tmp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f069ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/trend_train_k_20.pkl','wb') as f:\n",
    "    pickle.dump(trend_train,f)\n",
    "with open('data/trend_test_k_20.pkl','wb') as f:\n",
    "    pickle.dump(trend_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5825d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BID_PRICE1</th>\n",
       "      <th>BID_QTY_1</th>\n",
       "      <th>ASK_PRICE_1</th>\n",
       "      <th>ASK_QTY_1</th>\n",
       "      <th>BID_PRICE2</th>\n",
       "      <th>BID_QTY_2</th>\n",
       "      <th>ASK_PRICE_2</th>\n",
       "      <th>ASK_QTY_2</th>\n",
       "      <th>BID_PRICE3</th>\n",
       "      <th>BID_QTY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BID_PRICE9</th>\n",
       "      <th>BID_QTY_9</th>\n",
       "      <th>ASK_PRICE_9</th>\n",
       "      <th>ASK_QTY_9</th>\n",
       "      <th>BID_PRICE10</th>\n",
       "      <th>BID_QTY_10</th>\n",
       "      <th>ASK_PRICE_10</th>\n",
       "      <th>ASK_QTY_10</th>\n",
       "      <th>MID_PRICE</th>\n",
       "      <th>TREND_MID_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.243831e-01</td>\n",
       "      <td>1.708136e-03</td>\n",
       "      <td>7.225780e-01</td>\n",
       "      <td>2.263191e-03</td>\n",
       "      <td>7.243022e-01</td>\n",
       "      <td>1.370084e-03</td>\n",
       "      <td>7.222462e-01</td>\n",
       "      <td>1.767895e-03</td>\n",
       "      <td>7.243999e-01</td>\n",
       "      <td>1.441995e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.257788e-01</td>\n",
       "      <td>1.743585e-03</td>\n",
       "      <td>7.198853e-01</td>\n",
       "      <td>2.438933e-03</td>\n",
       "      <td>7.262230e-01</td>\n",
       "      <td>1.812457e-03</td>\n",
       "      <td>7.181023e-01</td>\n",
       "      <td>2.516551e-03</td>\n",
       "      <td>7.234805e-01</td>\n",
       "      <td>-1.078834e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.084827e-01</td>\n",
       "      <td>8.157408e-03</td>\n",
       "      <td>1.089586e-01</td>\n",
       "      <td>1.121440e-02</td>\n",
       "      <td>1.085240e-01</td>\n",
       "      <td>6.038045e-03</td>\n",
       "      <td>1.090480e-01</td>\n",
       "      <td>8.447833e-03</td>\n",
       "      <td>1.085274e-01</td>\n",
       "      <td>5.931701e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082640e-01</td>\n",
       "      <td>5.877173e-03</td>\n",
       "      <td>1.097558e-01</td>\n",
       "      <td>9.015122e-03</td>\n",
       "      <td>1.081734e-01</td>\n",
       "      <td>5.896087e-03</td>\n",
       "      <td>1.104199e-01</td>\n",
       "      <td>8.948883e-03</td>\n",
       "      <td>1.087204e-01</td>\n",
       "      <td>9.316808e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.800523e-01</td>\n",
       "      <td>6.071431e-05</td>\n",
       "      <td>6.780306e-01</td>\n",
       "      <td>8.796284e-05</td>\n",
       "      <td>6.800027e-01</td>\n",
       "      <td>5.025966e-05</td>\n",
       "      <td>6.776093e-01</td>\n",
       "      <td>7.311911e-05</td>\n",
       "      <td>6.801567e-01</td>\n",
       "      <td>6.360354e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>6.817964e-01</td>\n",
       "      <td>6.907378e-05</td>\n",
       "      <td>6.747114e-01</td>\n",
       "      <td>1.072070e-04</td>\n",
       "      <td>6.822774e-01</td>\n",
       "      <td>7.070571e-05</td>\n",
       "      <td>6.726517e-01</td>\n",
       "      <td>1.073899e-04</td>\n",
       "      <td>6.790756e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.347177e-01</td>\n",
       "      <td>2.203098e-04</td>\n",
       "      <td>7.329369e-01</td>\n",
       "      <td>3.210644e-04</td>\n",
       "      <td>7.346532e-01</td>\n",
       "      <td>1.598484e-04</td>\n",
       "      <td>7.325992e-01</td>\n",
       "      <td>2.334680e-04</td>\n",
       "      <td>7.347808e-01</td>\n",
       "      <td>1.709266e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>7.361405e-01</td>\n",
       "      <td>3.636972e-04</td>\n",
       "      <td>7.301854e-01</td>\n",
       "      <td>5.669529e-04</td>\n",
       "      <td>7.366193e-01</td>\n",
       "      <td>3.989199e-04</td>\n",
       "      <td>7.284889e-01</td>\n",
       "      <td>6.461689e-04</td>\n",
       "      <td>7.338271e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.825070e-01</td>\n",
       "      <td>7.303351e-04</td>\n",
       "      <td>7.809972e-01</td>\n",
       "      <td>1.050973e-03</td>\n",
       "      <td>7.824294e-01</td>\n",
       "      <td>5.180902e-04</td>\n",
       "      <td>7.807327e-01</td>\n",
       "      <td>7.509827e-04</td>\n",
       "      <td>7.825340e-01</td>\n",
       "      <td>6.248188e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>7.837173e-01</td>\n",
       "      <td>1.276992e-03</td>\n",
       "      <td>7.788038e-01</td>\n",
       "      <td>1.984609e-03</td>\n",
       "      <td>7.841344e-01</td>\n",
       "      <td>1.401519e-03</td>\n",
       "      <td>7.773553e-01</td>\n",
       "      <td>2.195181e-03</td>\n",
       "      <td>7.817519e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BID_PRICE1     BID_QTY_1   ASK_PRICE_1     ASK_QTY_1    BID_PRICE2  \\\n",
       "count  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   7.243831e-01  1.708136e-03  7.225780e-01  2.263191e-03  7.243022e-01   \n",
       "std    1.084827e-01  8.157408e-03  1.089586e-01  1.121440e-02  1.085240e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    6.800523e-01  6.071431e-05  6.780306e-01  8.796284e-05  6.800027e-01   \n",
       "50%    7.347177e-01  2.203098e-04  7.329369e-01  3.210644e-04  7.346532e-01   \n",
       "75%    7.825070e-01  7.303351e-04  7.809972e-01  1.050973e-03  7.824294e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          BID_QTY_2   ASK_PRICE_2     ASK_QTY_2    BID_PRICE3     BID_QTY_3  \\\n",
       "count  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   1.370084e-03  7.222462e-01  1.767895e-03  7.243999e-01  1.441995e-03   \n",
       "std    6.038045e-03  1.090480e-01  8.447833e-03  1.085274e-01  5.931701e-03   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    5.025966e-05  6.776093e-01  7.311911e-05  6.801567e-01  6.360354e-05   \n",
       "50%    1.598484e-04  7.325992e-01  2.334680e-04  7.347808e-01  1.709266e-04   \n",
       "75%    5.180902e-04  7.807327e-01  7.509827e-04  7.825340e-01  6.248188e-04   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       ...    BID_PRICE9     BID_QTY_9   ASK_PRICE_9     ASK_QTY_9  \\\n",
       "count  ...  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   ...  7.257788e-01  1.743585e-03  7.198853e-01  2.438933e-03   \n",
       "std    ...  1.082640e-01  5.877173e-03  1.097558e-01  9.015122e-03   \n",
       "min    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    ...  6.817964e-01  6.907378e-05  6.747114e-01  1.072070e-04   \n",
       "50%    ...  7.361405e-01  3.636972e-04  7.301854e-01  5.669529e-04   \n",
       "75%    ...  7.837173e-01  1.276992e-03  7.788038e-01  1.984609e-03   \n",
       "max    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "        BID_PRICE10    BID_QTY_10  ASK_PRICE_10    ASK_QTY_10     MID_PRICE  \\\n",
       "count  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   7.262230e-01  1.812457e-03  7.181023e-01  2.516551e-03  7.234805e-01   \n",
       "std    1.081734e-01  5.896087e-03  1.104199e-01  8.948883e-03  1.087204e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    6.822774e-01  7.070571e-05  6.726517e-01  1.073899e-04  6.790756e-01   \n",
       "50%    7.366193e-01  3.989199e-04  7.284889e-01  6.461689e-04  7.338271e-01   \n",
       "75%    7.841344e-01  1.401519e-03  7.773553e-01  2.195181e-03  7.817519e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       TREND_MID_PRICE  \n",
       "count     4.523864e+06  \n",
       "mean     -1.078834e-02  \n",
       "std       9.316808e-01  \n",
       "min      -1.000000e+00  \n",
       "25%      -1.000000e+00  \n",
       "50%       0.000000e+00  \n",
       "75%       1.000000e+00  \n",
       "max       1.000000e+00  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e0f128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BID_PRICE1</th>\n",
       "      <th>BID_QTY_1</th>\n",
       "      <th>ASK_PRICE_1</th>\n",
       "      <th>ASK_QTY_1</th>\n",
       "      <th>BID_PRICE2</th>\n",
       "      <th>BID_QTY_2</th>\n",
       "      <th>ASK_PRICE_2</th>\n",
       "      <th>ASK_QTY_2</th>\n",
       "      <th>BID_PRICE3</th>\n",
       "      <th>BID_QTY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BID_PRICE9</th>\n",
       "      <th>BID_QTY_9</th>\n",
       "      <th>ASK_PRICE_9</th>\n",
       "      <th>ASK_QTY_9</th>\n",
       "      <th>BID_PRICE10</th>\n",
       "      <th>BID_QTY_10</th>\n",
       "      <th>ASK_PRICE_10</th>\n",
       "      <th>ASK_QTY_10</th>\n",
       "      <th>MID_PRICE</th>\n",
       "      <th>TREND_MID_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.368382e-01</td>\n",
       "      <td>3.321310e-03</td>\n",
       "      <td>6.356375e-01</td>\n",
       "      <td>2.428604e-03</td>\n",
       "      <td>6.378413e-01</td>\n",
       "      <td>2.005472e-03</td>\n",
       "      <td>6.347423e-01</td>\n",
       "      <td>1.648559e-03</td>\n",
       "      <td>6.380259e-01</td>\n",
       "      <td>2.251894e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.381818e-01</td>\n",
       "      <td>3.580512e-03</td>\n",
       "      <td>6.317899e-01</td>\n",
       "      <td>2.818728e-03</td>\n",
       "      <td>6.384726e-01</td>\n",
       "      <td>3.810461e-03</td>\n",
       "      <td>6.317734e-01</td>\n",
       "      <td>2.985486e-03</td>\n",
       "      <td>6.362378e-01</td>\n",
       "      <td>-9.249943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.297077e-01</td>\n",
       "      <td>1.607249e-02</td>\n",
       "      <td>2.296686e-01</td>\n",
       "      <td>1.684914e-02</td>\n",
       "      <td>2.296838e-01</td>\n",
       "      <td>9.945955e-03</td>\n",
       "      <td>2.294845e-01</td>\n",
       "      <td>1.240778e-02</td>\n",
       "      <td>2.295771e-01</td>\n",
       "      <td>1.059624e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.298244e-01</td>\n",
       "      <td>1.240951e-02</td>\n",
       "      <td>2.285868e-01</td>\n",
       "      <td>1.293692e-02</td>\n",
       "      <td>2.298410e-01</td>\n",
       "      <td>1.273617e-02</td>\n",
       "      <td>2.285434e-01</td>\n",
       "      <td>1.261898e-02</td>\n",
       "      <td>2.296881e-01</td>\n",
       "      <td>9.042742e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.804393e-04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.042867e-01</td>\n",
       "      <td>2.088198e-04</td>\n",
       "      <td>4.030849e-01</td>\n",
       "      <td>1.509219e-04</td>\n",
       "      <td>4.053288e-01</td>\n",
       "      <td>1.272300e-04</td>\n",
       "      <td>4.024708e-01</td>\n",
       "      <td>1.144943e-04</td>\n",
       "      <td>4.056657e-01</td>\n",
       "      <td>1.515221e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.055556e-01</td>\n",
       "      <td>1.543044e-04</td>\n",
       "      <td>4.002485e-01</td>\n",
       "      <td>1.337446e-04</td>\n",
       "      <td>4.058957e-01</td>\n",
       "      <td>1.561917e-04</td>\n",
       "      <td>4.003163e-01</td>\n",
       "      <td>1.345886e-04</td>\n",
       "      <td>4.036858e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.273758e-01</td>\n",
       "      <td>7.181528e-04</td>\n",
       "      <td>7.262107e-01</td>\n",
       "      <td>5.062537e-04</td>\n",
       "      <td>7.284580e-01</td>\n",
       "      <td>3.953544e-04</td>\n",
       "      <td>7.251502e-01</td>\n",
       "      <td>3.587667e-04</td>\n",
       "      <td>7.286119e-01</td>\n",
       "      <td>4.141808e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>7.289116e-01</td>\n",
       "      <td>9.728148e-04</td>\n",
       "      <td>7.218708e-01</td>\n",
       "      <td>8.520520e-04</td>\n",
       "      <td>7.292517e-01</td>\n",
       "      <td>1.063620e-03</td>\n",
       "      <td>7.217892e-01</td>\n",
       "      <td>9.193313e-04</td>\n",
       "      <td>7.267933e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.347698e-01</td>\n",
       "      <td>2.228750e-03</td>\n",
       "      <td>8.335035e-01</td>\n",
       "      <td>1.508968e-03</td>\n",
       "      <td>8.357143e-01</td>\n",
       "      <td>1.211874e-03</td>\n",
       "      <td>8.325966e-01</td>\n",
       "      <td>1.022137e-03</td>\n",
       "      <td>8.358074e-01</td>\n",
       "      <td>1.350642e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>8.362812e-01</td>\n",
       "      <td>3.030308e-03</td>\n",
       "      <td>8.287393e-01</td>\n",
       "      <td>2.612441e-03</td>\n",
       "      <td>8.366213e-01</td>\n",
       "      <td>3.147187e-03</td>\n",
       "      <td>8.287586e-01</td>\n",
       "      <td>2.714561e-03</td>\n",
       "      <td>8.340799e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BID_PRICE1     BID_QTY_1   ASK_PRICE_1     ASK_QTY_1    BID_PRICE2  \\\n",
       "count  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   6.368382e-01  3.321310e-03  6.356375e-01  2.428604e-03  6.378413e-01   \n",
       "std    2.297077e-01  1.607249e-02  2.296686e-01  1.684914e-02  2.296838e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    4.042867e-01  2.088198e-04  4.030849e-01  1.509219e-04  4.053288e-01   \n",
       "50%    7.273758e-01  7.181528e-04  7.262107e-01  5.062537e-04  7.284580e-01   \n",
       "75%    8.347698e-01  2.228750e-03  8.335035e-01  1.508968e-03  8.357143e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          BID_QTY_2   ASK_PRICE_2     ASK_QTY_2    BID_PRICE3     BID_QTY_3  \\\n",
       "count  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   2.005472e-03  6.347423e-01  1.648559e-03  6.380259e-01  2.251894e-03   \n",
       "std    9.945955e-03  2.294845e-01  1.240778e-02  2.295771e-01  1.059624e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.272300e-04  4.024708e-01  1.144943e-04  4.056657e-01  1.515221e-04   \n",
       "50%    3.953544e-04  7.251502e-01  3.587667e-04  7.286119e-01  4.141808e-04   \n",
       "75%    1.211874e-03  8.325966e-01  1.022137e-03  8.358074e-01  1.350642e-03   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       ...    BID_PRICE9     BID_QTY_9   ASK_PRICE_9     ASK_QTY_9  \\\n",
       "count  ...  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   ...  6.381818e-01  3.580512e-03  6.317899e-01  2.818728e-03   \n",
       "std    ...  2.298244e-01  1.240951e-02  2.285868e-01  1.293692e-02   \n",
       "min    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    ...  4.055556e-01  1.543044e-04  4.002485e-01  1.337446e-04   \n",
       "50%    ...  7.289116e-01  9.728148e-04  7.218708e-01  8.520520e-04   \n",
       "75%    ...  8.362812e-01  3.030308e-03  8.287393e-01  2.612441e-03   \n",
       "max    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "        BID_PRICE10    BID_QTY_10  ASK_PRICE_10    ASK_QTY_10     MID_PRICE  \\\n",
       "count  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   6.384726e-01  3.810461e-03  6.317734e-01  2.985486e-03  6.362378e-01   \n",
       "std    2.298410e-01  1.273617e-02  2.285434e-01  1.261898e-02  2.296881e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  6.804393e-04   \n",
       "25%    4.058957e-01  1.561917e-04  4.003163e-01  1.345886e-04  4.036858e-01   \n",
       "50%    7.292517e-01  1.063620e-03  7.217892e-01  9.193313e-04  7.267933e-01   \n",
       "75%    8.366213e-01  3.147187e-03  8.287586e-01  2.714561e-03  8.340799e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       TREND_MID_PRICE  \n",
       "count     2.403150e+06  \n",
       "mean     -9.249943e-03  \n",
       "std       9.042742e-01  \n",
       "min      -1.000000e+00  \n",
       "25%      -1.000000e+00  \n",
       "50%       0.000000e+00  \n",
       "75%       1.000000e+00  \n",
       "max       1.000000e+00  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830a05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tmp.to_csv('data/sets/test_set_k_20.csv',columns=list(df_test_tmp.columns.values))\n",
    "df_train_tmp.to_csv('data/sets/train_set_k_20.csv',columns=list(df_train_tmp.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bf9c2",
   "metadata": {},
   "source": [
    "## Set balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd61b4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAJtCAYAAACfeeVIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4pElEQVR4nO3de7itdVkv/O8tSNnGaie4gGyJ2yzTLMxVbTEVqlVuzLaHEjVTMiPEVOS10v1aZttDnkiyiLBtiOkONd9ee8MN5jkgbeEp1MgDYCosF2LmCTG83z/GWDmdz5xrjbWYY8w1xvh8rmtcc47f83uecY9rMtbNdzyn6u4AAADASrfY7AIAAAA48AiLAAAADAiLAAAADAiLAAAADAiLAAAADAiLAAAADAiLSarqZVX16aq6fML5D62qD1bVB6rqVdOuDwA2g/4IsNzKfRaTqrpPki8kOa+7v38vc++U5NVJfry7P1tVt+3uT8+iTgCYJf0RYLnZs5iku9+e5PqVY1V1x6r6P1V1WVW9o6ruPF70K0n+qLs/O15XIwRgIemPAMtNWFzfOUme0N33SPKUJGeNx78nyfdU1cVV9fdVdb9NqxAAZk9/BFgSB292AQeiqjo0ybFJXlNVu4e/afzz4CR3SnJcktsleXtV3a27/3XGZQLATOmPAMtFWFzbLZL8a3cfs8ayTyR5Z3d/NcmVVfXPGTXHf5hhfQCwGfRHgCXiMNQ1dPe/ZdTofj5JauQHx4v/KqNvTVNVh2V02M3HNqFMAJgp/RFguQiLSarqfye5NMn3VtUnquqXk/xCkl+uqvcl+UCS/z6efmGSz1TVB5O8Jcmvd/dnNqNuAJgm/RFgubl1BgAAAAP2LAIAADAgLAIAADCw1FdDPeyww/roo4/e7DIAmIHLLrvsuu4+fLPrmBd6JMBy2FN/XOqwePTRR2fHjh2bXQYAM1BVV292DfNEjwRYDnvqjw5DBQAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYGCmYbGqnlZV/1BV/1ZVu6rqr6vq+ydY725V9baq+nJVfbKqfruqatWch1TVB6vqK+OfD5reOwGA2aqq+1TV68d9sKvqpAnW2Wv/BID1zHrP4nFJzkpybJIfT/LvSf62qr5jvRWq6luTvDHJziQ/nORJSX49yekr5twzyflJXpnkmPHP11TVj07jTQDAJjg0yeUZ9cEv723yJP0TAPbk4Fm+WHf/9MrnVfWLST6X5F5J/nqd1X4hybckeXR3fznJ5VV15ySnV9UZ3d1JTkvylu5+9nidZ1fV8ePxh2/4GwGAGevuC5JckCRVde4Eq0zSPwFgXZt9zuKtxzV8dg9z7pnkHeNGt9uFSY5KcvSKORetWu/CjPZgAsAymqR/AsC6NjssnpnkvUku3cOcIzI6hGalnSuW7WnOEQGA5TRJ/wSAdW1aWKyqM5L8WJKHdPdNM3zdk6tqR1Xt2LVr16xeFgAOeHokACttSlisqt/P6FzCH+/uj+1l+rVJtqwa27Ji2Z7mXLtqLN19Tndv6+5thx9++L4VDgDzY5L++Q30SABWmnlYrKoz8/Wg+E8TrHJpkntX1TevGNue5FNJrloxZ/uq9bYnueTmVQsAc2uS/gkA65rp1VCr6o+S/GKSByb5bFXtPmfiC939hfGc5yb5ke7+ifGyVyV5RpJzq+pZSb4nyVOTPHPFldzOTPL2qnpqkr9K8qAkx2d0mOsB6+in/s1ml7Cprvq9+292CQBzo6oOTfLd46e3SLK1qo5Jcn13f3w/++cBa5l7pP4IHChmvWfx1IyugPqmJNeseDxlxZwjk9xx95Pu/lxG34QelWRHkj9K8qIkZ6yYc0mShyU5Kcn7kzwqyYnd/c7pvRUAmKltSd4zftwqyTPHv//uePk+908A2JNZ32exJphz0hpj/5jkPntZ77VJXrvfxQHAAay735pk3T66v/0TANaz2bfOAAAA4AAkLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADBw8GYXAAAAux391L/Z7BI2zVW/d//NLgG+gbAIm0AjBADgQOcwVAAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAZmGhar6j5V9fqq+mRVdVWdtJf5vzOet9bjtuM5R6+z/H4zeVMAAAAL6OAZv96hSS5Pct74sTcvTHL2qrG/SNLd/elV4/dL8r4Vz6/f3yIBAACW3UzDYndfkOSCJKmqcyeY/4UkX9j9vKq+K8m9k/ziGtM/093XbkylAAAAy23ezln85SSfTfKXayx7XVV9uqourqqfm3FdAAAAC2VuwmJVHZTkMUle0d1fWbHoC0mekuShSU5I8qYk51fVI9fZzslVtaOqduzatWvaZQMAAMylWZ+zeHPcL8l3JXnpysHuvi7Ji1YM7aiqw5L8RpI/X72R7j4nyTlJsm3btp5atQAAAHNsbvYsJjk5ySXd/cEJ5r4zyZ2mXA8AAMDCmos9i1V1VJL7J3nshKsck+SaqRUEAACw4GYaFqvq0CTfPX56iyRbq+qYJNd398er6rlJfqS7f2LVqo9J8sUkr15jm49O8tUk70nytSQPSPL4JL85lTcBAACwBGa9Z3FbkreseP7M8ePlSU5KcmSSO65coaoqo6ugvrK7v7TOdp+e5PZJbkryz0ke092D8xUBAACYzKzvs/jWJLWH5SetMdZJ7rCHdV6eUdgEAABgg8zTBW4AAACYEWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAOZIVZ1aVVdW1Q1VdVlV3Xsv8x9RVe+tqi9V1bVV9edVdcSs6gVgfgmLADAnqurEJGcmeU6Suye5JMkbqmrrOvPvleQVSV6e5K5JHpjkLkleOYt6AZhvwiIAzI/Tk5zb3S/t7g919xOSXJPkcevMv2eST3T373f3ld3990lekuRHZ1QvAHNMWASAOVBVhyS5R5KLVi26KMmx66x2cZIjq+oBNXJYkocluWB6lQKwKIRFAJgPhyU5KMnOVeM7k6x5DmJ3X5pROHxlkhuT7EpSSR691vyqOrmqdlTVjl27dm1U3QDMKWERABZUVd0lo8NO/2dGeyXvl1Gw/JO15nf3Od29rbu3HX744bMrFIAD0sGbXQAAMJHrktyUZMuq8S1Jrl1nnacleVd3v2D8/P1V9cUk76iq/9Hdn5hOqQAsAnsWAWAOdPeNSS5Lsn3Vou0ZXRV1Ld+SUcBcafdz/w8AwB7ZswgA8+OMJK+oqndldPGaU5IcleTsJKmq85Kkux81nv/XSV5aVY9LcmGSI5O8OMm7u/vjsy0dgHkjLALAnOju86vqNkmenlHwuzzJCd199XjK1lXzz62qWyf5tSQvSvK5JG9O8puzqxqAeSUsAsAc6e6zkpy1zrLj1hh7SUYXuQGAfeJ8BQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAaERQAAAAZmGhar6j5V9fqq+mRVdVWdtJf5R4/nrX7cb9W8+1bVZVV1Q1V9rKpOmeobAQAAWHCz3rN4aJLLkzwpyZf3Yb37JTlyxePNuxdU1R2SXJDkkiR3T/LcJC+pqodsUM0AAABL5+BZvlh3X5BRsEtVnbsPq36mu69dZ9kpST7V3U8YP/9QVf1okqck+cv9rRUAAGCZzcs5i6+rqk9X1cVV9XOrlt0zyUWrxi5Msq2qbjmb8gAAABbLgR4Wv5DRHsKHJjkhyZuSnF9Vj1wx54gkO1ettzOjvaaHrd5gVZ1cVTuqaseuXbumUzUAAMCcm+lhqPuqu69L8qIVQzuq6rAkv5Hkz/dzm+ckOSdJtm3b1je7SAAAgAV0oO9ZXMs7k9xpxfNrk2xZNWdLkn9Pct2sigIAAFgk8xgWj0lyzYrnlybZvmrO9iQ7uvursyoKAABgkcz0MNSqOjTJd4+f3iLJ1qo6Jsn13f3xqnpukh/p7p8Yz390kq8meU+SryV5QJLHJ/nNFZs9O8mvVdWLk/xJknslOSnJw6f9fgAAABbVrM9Z3JbkLSueP3P8eHlGAe/IJHdctc7Tk9w+yU1J/jnJY7r7P85X7O4rq+qEJL+f5HFJPpXkid3tthkAAAD7adb3WXxrktrD8pNWPX95RkFyb9t9W5IfupnlAQAAMDaP5ywCAAAwZcIiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA8IiAAAAA/sdFqvqlhtZCAAsE30UgAPdRGGxqp5YVQ9Z8fx/JflyVV1RVd87teoAYAHoowDMo0n3LD4xya4kqar7JHlokkckeW+SF02lMgBYHPooAHPn4AnnfWeSK8e/PyDJa7r71VX1j0neMZXKAGBx6KMAzJ1J9yz+W5Lbjn/fnuRN49+/muSbN7ooAFgw+igAc2fSPYsXJXlpVb07yXcnecN4/K75+jelAMDa9FEA5s6kexYfn+TiJIcn+bnuvn48/kNJ/vc0CgOABaKPAjB3Jtqz2N3/luQJa4w/Y8MrAoAFo48CMI8mvXXGTVV12zXGb1NVN218WQCwOPRRAObRpIeh1jrj35Tkxg2qBQAWlT4KwNzZ42GoVXX6+NdOckpVfWHF4oOS3DvJP036YuN7Sz0lyT2SHJXkl7r73D3MPy7Jk5P8SJJvS/KRJC/u7petmvOWNVb/vu6euDYA2Ggb3UcBYJb2ds7i7vMrKsljk6w8VObGJFclOWUfXu/QJJcnOW/82Jtjk/xjkucnuSbJTyc5p6pu6O5XrZp71yTXr3i+ax/qAoBp2Og+CgAzs8ew2N13SJKqekuSB3f3Z2/Oi3X3BUkuGG/z3AnmP2fV0B9X1fFJHpJkdVj8dHdfd3PqA4CNtNF9FABmaaJzFrv7+AOowX1rkrVq2VFV11TVm8aBEgAOCAdYHwWAiUx064wkqaoTk/xEkttmVcjs7p/d4LrWq+FnxjXca8XwNUkel+QfkhyS5BeTvKmq7tvd71hjGycnOTlJtm7dOvWaASA5MPooAOyLicJiVb0gyWkZXUjmUxmdqD9TVXWvjA49fWJ3v2v3eHdfkeSKFVMvraqjk/x6kkFY7O5zkpyTJNu2bZv5+wBg+RwIfRQA9tWkexYfleTh3f3aaRaznqr6sYzOdfzt7v7jCVZ5Z5KHTbcqAJjYpvZRANgfk95n8RZJ3jvFOtY1vt3GG5L8Tne/eMLVjsno8FQAOBBsWh8FgP01aVg8J8kjb+6LVdWhVXVMVR0zfu2t4+dbx8ufW1VvWjH/uIyC4tlJXlVVR4wfh6+Yc1pVPbCq7lRVd62q5yZ5YJI/vLn1AsAG2ZA+CgCzNOlhqN+e5BFVtT3J+5N8deXC7n7ihNvZltH5Grs9c/x4eZKTkhyZ5I4rlp+U5FuSPGX82O3qJEePfz8kyQuS3C7Jl5N8IMn9x7fpAIADwbdnY/ooAMzMpGHxLvn64TN3XrVs4pP0u/utGd2YeL3lJ63x/KS15q6Y8/wkz5+0BgDYBBvSRwFgliYKi93tvoUAsJ/0UQDm0aTnLAIAALBEJr3P4uv3tNzNhAFgfRvZR6vq1IzuJXxkRufpn9bdg/sKr5h/SJKnJ/nFJEcl2Znkhd39B5O+JgDLadJzFj+z6vktk/xgku9K8roNrQgAFs+G9NGqOjHJmUlOTfJ3459vqKq7dPfH11ntLzK6CNzJST6cZEuSW+1T9QAspUnPWfyltcar6kVJ/m1DKwKABbOBffT0JOd290vHz59QVfdL8rgkT1tj+z+V5CeS3LG7rxsPX7UPrwfAEru55yz+SZLHb0QhALCEJu6j48NJ75HkolWLLkpy7DqrPTDJPyQ5vao+UVUfrqo/qKpD97NeAJbIpIehrud7N6QKAFhO+9JHD0tyUEbnHK60M8lPrrPOf0nyY0m+kuQhGd3v8SUZnbv4c6snV9XJGR2umq1bt+5DaQAsokkvcLP6JPjK6MT6/5bkZRtdFAAskk3so7fI6D6Oj+juz41r+bUkF1bVlu7+huDZ3eckOSdJtm3b5v6PAEtu0j2Ld1v1/GtJdiV5coRFANibjeij1yW5KaML1Ky0Jcm166xzTZJP7g6KYx8a/9ya4V5KAPgPk17gxs2EAWA/bUQf7e4bq+qyJNuTvGbFou1J/nKd1S5O8vNVdWh3f2E89j3jn1ff3JoAWGz7dIGbqvrmqvr+qrprVX3ztIoCgEW0AX30jCQnVdVjq+r7qurMjM4/PHu8/fOq6rwV81+V0W07/mz8mvfK6NYbr+3uT9/MtwPAgpsoLFbVLavqBUk+m+R9Sf4xyWer6vlVdctpFggA826j+mh3n5/ktCRPT/LejC5ec0J3795LuHX82D3/Cxld/ObbMroq6quTvC3JY27mWwJgCUx6zuLzkjw8ySkZ3QQ4Se6d5LkZBc6nbHxpALAwNqyPdvdZSc5aZ9lxa4xdkeSn9q1cAJg8LD4iyWO6+4IVYx+tql1J/jTCIgDsiT4KwNyZ9JzFb0vy0TXGP5rRPZsAgPXpowDMnUnD4vuSPHGN8SdldM4EALA+fRSAuTPpYai/keSCqvrJJH8/HvuvGV2B7b9NozAAWCD6KABzZ6I9i9399iTfm+S1SQ4dP16T5Hu7++/2tC4ALDt9FIB5NOmexXT3J5P831OsBQAWlj4KwLyZ9D6Lv1ZVj1xj/JFVderGlwUAi0MfBWAeTXqBm9OS/Msa41clefJGFQMAC+q06KMAzJlJw+Ltkly9xvgnxssAgPXpowDMnUnD4rVJjllj/IeSXLdh1QDAYtJHAZg7k17g5lVJ/qCqvpjkreOx45O8OMkrN74sAFgo+igAc2fSsPiMJHdIcmGSm8Zjt8jost+/NYW6AGCR6KMAzJ2JwmJ3fzXJw6vqt5LcfTz83u7+8NQqA4AFoY8CMI8mvs9iknT3R5J8ZEq1AMBC00cBmCeTXuAGAACAJSIsAgAAMCAsAgAAMCAsAgAAMLBPF7ipqqOS3DarQmZ3v3sjiwKARaSPAjBPJgqLVXX3JH+e5M5JatXiTnLQBtcFAAtDHwVgHk26Z/GcJP+S5FeSfCqjxgYATEYfBWDuTBoW75Lk7t39z9MsBgAWlD4KwNyZ9AI3/5jkiGkWAgALTB8FYO5MGhb/R5LnV9VPVtWWqvqOlY9pFggAC0AfBWDuTHoY6t+Of16UbzzPouLEfADYG30UgLkzaVg8fqpVAMBi00cBmDsThcXuftu0CwGARaWPAjCPJt2zmKrakuTxGV3RrZN8IMkfd/fOKdUGAAtDHwVg3kx0gZuquleSjyR5RJIvJ7khySOTfLiq7jm98gBg/umjAMyjSfcsvjDJ/05ySnd/LUmq6hZJzk7yoiTHTqc8AFgI+igAc2fSsHhMkpN2N7gk6e6vVdUZSd4zjcIAYIEcE30UgDkz6X0WP5fkDmuM3yHJv25YNQCwmPRRAObOpHsW/yLJ/6qq30hyyXjsXkmel9FhNQDA+vRRAObOpGHxNzK6cfDLVqzz1SR/nOSpU6gLABaJPgrA3Jn0Pos3JnlSVT0tyR3Hwx/t7i9NrTIAWBD6KADzaOL7LCbJuKn945RqAYCFpo8CME/WDYtV9fokj+zufxv/vq7u/tkNrwwA5pg+CsC829Oexc8k6fHv16/4HQDYO30UgLm2bljs7l9a8ftJM6kGABaEPgrAvJvoPotV9bKquvUa4/+pql628WUBwOLQRwGYRxOFxSSPTnKrNcZvleRRG1cOACwkfRSAubPHsFhV31FVt8no3lD/efx89+PwJD+TZOekL1ZV96mq11fVJ6uqq+qkCda5W1W9raq+PF7vt6uqVs15SFV9sKq+Mv75oElrAoBp2eg+CgCztLdbZ1yX0Qn5neSDayzvJM/Yh9c7NMnlSc4bP/aoqr41yRuTvD3JDye5c5I/S/LFJC8az7lnkvPHdbwuyYOTvKaq7tXd79yH2gBgo210HwWAmdlbWDw+o29D35zkIRldzW23G5Nc3d2fmvTFuvuCJBckSVWdO8Eqv5DkW5I8uru/nOTyqrpzktOr6ozu7iSnJXlLdz97vM6zq+r48fjDJ60NAKZgQ/soAMzSHsNid78tSarqDkn+pbu/NpOqvu6eSd4xDoq7XZjkfyY5OsmV4zkvWbXehUl+bRYFAsB6DoA+CgD7bW97FpMk3X11klTVUUm2Jjlk1fK3b3xpSZIjknxi1djOFcuuHP9cfb7HzvH4QFWdnOTkJNm6deuGFQoA69nEPgoA+22isDhubq9Kcp+Mzq+ofOPNhQ/a+NKmo7vPSXJOkmzbts0NkgGYukXqowAsj0lvnfHiJDcluUuSLyW5d5KfT/KhJPebSmUj1ybZsmpsy4ple5pzbQDgwPDibE4fBYD9NtGexST3TXL/7v6nquoku7r74qr6SkbnD75xSvVdmuR5VfXN3X3DeGx7kk8luWrFnO1JXrBive1JLplSTQCwrzarjwLAfpt0z+KtMrr8dzK6ktttx79/MMkPTPpiVXVoVR1TVceMX3vr+PnW8fLnVtWbVqzyqoy+gT23qr6/qh6c5KlJdl8JNUnOTPLjVfXUqrpzVT0to6vPvXjSugBgyjakjwLALE0aFv8po3scJsl7k5xSVbdP8vgkn9yH19uW5D3jx62SPHP8+++Olx+Z5I67J3f35zLaS3hUkh1J/iij+yuesWLOJUkeluSkJO9P8qgkJ7rHIgAHkI3qowAwM5Mehnpmvn510d9N8n8yuofhV5I8etIX6+63ZnRS/3rLT1pj7B8zuiDAnrb72iSvnbQOAJixDemjADBLk94645Urfn93VR2d0TekH+/u69ZdEQDQRwGYSxMdhlpVD6yqW+5+3t1f6u53a3AAsHf6KADzaNJzFl+V5NqqOruq7jXNggBgAemjAMydScPiliRPyejiM2+rqo9V1bOq6s57WQ8A0EcBmEMThcXu/nx3/1l3b0+yNckfZnQT4Q9U1T9Ms0AAmHf6KADzaNKrof6H7v5UVf1hkquTPD3JD214VQCwoPRRAObFpIehJkmq6viq+tMkO5P8aZJ3J/nJaRQGAItGHwVgnky0Z7GqXpjkxCS3zejeUCcneX13f2WKtQHAQtBHAZhHkx6Ges8kz0lyfndfP8V6AGAR6aMAzJ29HoY6vi/UJ5JcpMEBwL7RRwGYV3sNi9391SQ/laSnXw4ALBZ9FIB5NekFbl6X5MHTLAQAFpg+CsDcmfScxY8neXpV3TvJjiRfXLmwu8/Y6MIAYIHoowDMnUnD4klJPpvkB8aPlTqJJgcA6zsp+igAc2aisNjdd5h2IQCwqPRRAObRpOcs/oeq2lJV+7weAKCPAjA/JmpWVXXLqnp+VX0+ySeTHD0ef15VnTrF+gBg7umjAMyjSb/ZfEaSByR5ZJKvrBh/V0bnYQAA69NHAZg7k17g5uFJHtPdb6uqr60YvzzJ92x8WQCwUPRRAObOpHsWj0py9RrjB2fywAkAy0ofBWDuTBoWP5DkPmuMPzTJZRtXDgAsJH0UgLkz6beZz0zy51X1XUkOSvLzVXXnJI9Icv9pFQcAC0IfBWDuTLRnsbv/OqNvP38qydcyOlH/Tkke0N1/O73yAGD+6aMAzKOJz5Po7guTXDjFWgBgYemjAMybSe+zeHhVHb7i+d2q6llV9fDplQYAi0EfBWAeTXqBm1dndH+oVNVhSd6e5EFJzq6q/2tKtQHAotBHAZg7kx6G+gNJ/n78+88l+Uh3/3BV/fckL0jyomkUBwALQh8F2IOjn/o3m13Cprrq9w7Ma51NumfxVkm+MP79J5O8fvz7u5N810YXBQALRh8FYO5MGhY/nOTB40t+/1SSi8bjW5L86xTqAoBFoo8CMHcmDYvPTPK8JFcl+fvufud4/KeTvGcKdQHAItFHAZg7E52z2N2vq6qtSY5K8r4Vi/42yV9OozAAWBT6KADzaF/us7gzyc6qOrSq0t1fWPHNKACwB/ooAPNm0sNQU1WnVdXHk3wuyeeq6l+q6slVVdMrDwAWgz4KwLyZaM9iVT0/yckZXd770vHwPZP8dpIjk/zGVKoDgAWgjwIwjyY9DPWxSR7b3a9dMfbmqroiyZ9EkwOAPdFHAZg7Ex+GmuT964ztyzYAYFnpowDMlUkb1HlJHr/G+OOSvGLjygGAhaSPAjB31j0Mtar+YNW8R1bVTyf5+/HYj2Z0CfBXTq88AJhP+igA825P5yzebdXzy8Y/bz/+ee34ceeNLgoAFoA+CsBcWzcsdvfxsywEABaJPgrAvJv0aqipqm9Lcqfx0490979OpSIAWED6KADzZq8XuKmqrVX110k+k+Sd48d1VfX6qrr9ntcGgOW20X20qk6tqiur6oaquqyq7j3hej9WVf9eVZfv62sCsJz2uGexqr4zoxPxv5bRjYM/OF501ySnJrmkqn64uz811SoBYA5tdB+tqhOTnDle9+/GP99QVXfp7o/vYb3/nNEVWd+U5Dv38+0AsGT2tmfxGUmuTHKn7n5Od//V+PHsjA6luXI8BwAY2ug+enqSc7v7pd39oe5+QpJrMroFx578ryQvT3Lpvr8FAJbV3sLiCUn+R3d/efWC7v5Skqcnuf80CgOABbBhfbSqDklyjyQXrVp0UZJj97DeqUm2JHnWhDUDQJK9h8XDk3x0D8s/Mp4DAAxtZB89LMlBSXauGt+Z5Ii1Vqiqu2W05/KR3X3T3l6gqk6uqh1VtWPXrl0TlgXAotpbWPx0ku/ew/I7jecAAEOb1ker6puSnJ/kKd195STrdPc53b2tu7cdfrjvggGW3d7C4huSPGvccL5BVX1zkv+Z5IJpFAYAC2Aj++h1SW7K6JDSlbYkuXaN+Ucm+b4kfza+Cuq/Z3SRnbuOn//UhK8LwJLa230WfyfJjiQfqao/TPJP4/G7ZHQFtoOTnDi16gBgvv1ONqiPdveNVXVZku1JXrNi0fYkf7nGKp9McrdVY6eO5z8oyVUTvQMAltYew2J3f6qqjk1yVpLnJKndi5JcmOTXuvuT0y0RAObTFProGUleUVXvSnJxklOSHJXk7CSpqvPGr/uo7v5qkm+4p2JVfTrJV7rbvRYB2Ku97VlMd1+V5ITxPZruNB7+SHdfP83CAGARbGQf7e7zq+o2GV1F9ciMwuAJ3X31eMrWDSgZAJJMEBZ36+7PJnnXFGsBgIW1UX20u8/KaE/lWsuO28u6v5PRobEAsFd7u8ANAAAAS0hYBAAAYGDmYbGqTq2qK6vqhqq6rKruvYe551ZVr/H44oo5x60z586zeUcAAACLZ6ZhsapOTHJmRleEu3uSS5K8oarWOyH/SRmdwL/y8bEkr15j7l1XzfvwhhYPAACwRGa9Z/H0JOd290u7+0Pd/YQk1yR53FqTu/tz3X3t7keSOyb5L0leusb0T6+c2903Te1dAAAALLiZhcWqOiTJPZJctGrRRUmOnXAzv5LkA919yRrLdlTVNVX1pqo6/maUCgAAsPRmuWfxsCQHJdm5anxnkiP2tnJVfVuSh2a4V3H3nsmHJHlwkiuSvGm9cyGr6uSq2lFVO3bt2rVv7wAAAGBJTHyfxQPAIzMKt69YOdjdV2QUEHe7tKqOTvLrSd6xeiPdfU6Sc5Jk27ZtPa1iAQAA5tks9yxel+SmJFtWjW9Jcu0E6/9Kkr/s7usnmPvOJHfat/IAAADYbWZhsbtvTHJZku2rFm3P6Kqo66qqH0nyg1n7wjZrOSajw1MBAADYD7M+DPWMJK+oqncluTjJKUmOSnJ2klTVeUnS3Y9atd7JST7c3W9dvcGqOi3JVUk+kOSQjA5XfWBG5zACAACwH2YaFrv7/Kq6TZKnZ3QvxMuTnNDdV4+nDO63WFW3TvKwJL+7zmYPSfKCJLdL8uWMQuP9u/uCDS4fAABgacz8AjfdfVaSs9ZZdtwaY59Pcugetvf8JM/fqPoAAACY7QVuAAAAmBPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAPCIgAAAAMHb3YBAMvk6Kf+zWaXsGmu+r37b3YJAMA+sGcRAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAAWERAACAgZmHxao6taqurKobquqyqrr3HuYeV1W9xuPOq+Y9pKo+WFVfGf980PTfCQAAwOKaaVisqhOTnJnkOUnunuSSJG+oqq17WfWuSY5c8fjwim3eM8n5SV6Z5Jjxz9dU1Y9udP0AAADLYtZ7Fk9Pcm53v7S7P9TdT0hyTZLH7WW9T3f3tSseN61YdlqSt3T3s8fbfHaSt47HAQAA2A8zC4tVdUiSeyS5aNWii5Icu5fVd1TVNVX1pqo6ftWye66xzQsn2CYAAADrmOWexcOSHJRk56rxnUmOWGed3XsdH5LkwUmuSPKmVec5HrGP2wQAAGAvDt7sAvaku6/IKCDudmlVHZ3k15O8Y3+2WVUnJzk5SbZu3dupkgAAAMtplnsWr0tyU5Itq8a3JLl2H7bzziR3WvH82n3ZZnef093bunvb4Ycfvg8vCwAAsDxmFha7+8YklyXZvmrR9oyuijqpYzI6PHW3SzdgmwAAAKww68NQz0jyiqp6V5KLk5yS5KgkZydJVZ2XJN39qPHz05JcleQDSQ5J8sgkD8zoHMbdzkzy9qp6apK/SvKgJMcn+bEpvxcAAICFNdOw2N3nV9Vtkjw9o/slXp7khO6+ejxl9UmEhyR5QZLbJflyRqHx/t19wYptXlJVD0vyrCS/m+SjSU7s7ndO9c0AAAAssJlf4Ka7z0py1jrLjlv1/PlJnj/BNl+b5LUbUR8AAACzvcANAAAAc0JYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBAAAYEBYBIA5UlWnVtWVVXVDVV1WVffew9wHV9VFVbWrqj5fVe+sqp+dZb0AzC9hEQDmRFWdmOTMJM9JcvcklyR5Q1VtXWeV+yZ5c5L7j+dfkOT/2VPABIDdDt7sAgCAiZ2e5Nzufun4+ROq6n5JHpfkaasnd/eTVg09s6run+SBSd4xzUIBmH/2LALAHKiqQ5LcI8lFqxZdlOTYfdjUrZN8dqPqAmBxCYsAMB8OS3JQkp2rxncmOWKSDVTV45PcLskrNrY0ABaRsAgAS6CqHpLkBUke0d1XrzPn5KraUVU7du3aNdsCATjgCIsAMB+uS3JTki2rxrckuXZPK1bVz2W0N/FR3f3X683r7nO6e1t3bzv88MNvbr0AzDlhEQDmQHffmOSyJNtXLdqe0VVR11RVD80oKJ7U3a+dXoUALBpXQwWA+XFGkldU1buSXJzklCRHJTk7SarqvCTp7keNnz8so6D4lCRvr6rd5zbe2N3Xz7h2AOaMsAgAc6K7z6+q2yR5epIjk1ye5IQV5yCuvt/iKRn1+hePH7u9Lclx06wVgPknLALAHOnus5Kctc6y4/b0HAD2hXMWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGBAWAQAAGJh5WKyqU6vqyqq6oaouq6p772Hug6vqoqraVVWfr6p3VtXPrppzUlX1Go9vnv67AQAAWEwzDYtVdWKSM5M8J8ndk1yS5A1VtXWdVe6b5M1J7j+ef0GS/2eNgPmlJEeufHT3DRv/DgAAAJbDwTN+vdOTnNvdLx0/f0JV3S/J45I8bfXk7n7SqqFnVtX9kzwwyTu+cWpfO4V6AQAAltLM9ixW1SFJ7pHkolWLLkpy7D5s6tZJPrtq7FZVdXVVfaKq/r+quvvNKBUAAGDpzfIw1MOSHJRk56rxnUmOmGQDVfX4JLdL8ooVw1ckeUyS/57k4UluSHJxVd3p5hYMAACwrGZ9GOp+q6qHJHlBkhO7++rd4919aZJLV8y7JMl7kzwhyRPX2M7JSU5Okq1b1ztVEgAAYLnNcs/idUluSrJl1fiWJHs837Cqfi6jvYmP6u6/3tPc7r4pyY4ka+5Z7O5zuntbd287/PDDJ60dAABgqcwsLHb3jUkuS7J91aLtGV0VdU1V9dCMguJJ3f3avb1OVVWSH0hyzf5XCwAAsNxmfRjqGUleUVXvSnJxklOSHJXk7CSpqvOSpLsfNX7+sIyC4lOSvL2qdp/beGN3Xz+e84wkf5/kw0m+NaNDT38goyusAgAAsB9mGha7+/yquk2Sp2d0P8TLk5yw4hzE1ScRnpJRjS8eP3Z7W5Ljxr9/e5JzMrpIzueSvCfJfbr7XRv+BgAAAJbEzC9w091nJTlrnWXH7en5Ous8OcmTN6I2AAAARmZ5gRsAAADmhLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAgLAIAADAwKaExao6taqurKobquqyqrr3Xubfdzzvhqr6WFWdcnO3CQDzaBo9FADWMvOwWFUnJjkzyXOS3D3JJUneUFVb15l/hyQXjOfdPclzk7ykqh6yv9sEgHk0jR4KAOvZjD2Lpyc5t7tf2t0f6u4nJLkmyePWmX9Kkk919xPG81+a5OVJnnIztgkA82gaPRQA1jTTsFhVhyS5R5KLVi26KMmx66x2zzXmX5hkW1Xdcj+3CQBzZRo9dGMrBGDRzHrP4mFJDkqyc9X4ziRHrLPOEevMP3i8vf3ZJgDMm2n0UABY18GbXcCsVdXJSU4eP/1CVV2xmfVsssOSXLdZL17P26xXJpv4t/d331TL/pm//WYXcKDTI//Dsn9Wlpm//fJa5r/9uv1x1mHxuiQ3JdmyanxLkmvXWefadeb/+3h7tS/b7O5zkpyzT1UvqKra0d3bNrsOZs/ffjn5u8+9afTQb6BHjvisLC9/++Xlb7+2mR6G2t03JrksyfZVi7ZndKW2tVy6zvwd3f3V/dwmAMyVafTQja0QgEWzGVdDPSPJSVX12Kr6vqo6M8lRSc5Okqo6r6rOWzH/7CTfWVUvHs9/bJKTkrxw0m0CwIKYRg8FgDXN/JzF7j6/qm6T5OlJjkxyeZITuvvq8ZStq+ZfWVUnJPn9jC4N/qkkT+zuv9yHbbK2pT/UaIn52y8nf/c5N40eypp8VpaXv/3y8rdfQ3X3ZtcAAADAAWYzDkMFAADgACcsAgAAMCAsAgAAMDDzC9ywearqoIxuOJok13X3TZtZDzB9PvcwGZ8VWD4+93tnz+ISqKoHVdXFSb6U0ZXwPpXkS1V1cVU9cFOLY2aq6vZV9aPjx+03ux6my+ceJuOzQqJHLhuf+8kJiwuuqn41yflJPpjkF5IcN378QpIPJPmLqvqVzaqP6auqJ1fVvyT5WEY36L40yceq6l+q6rRNLY6p8LmHyfisoEcuH5/7fePWGQuuqj6S5Pe6+0/XWf7YJE/r7jvOtjJmoap+K8mvJ3lekguT7Bwv2pLkp5L8ZpIXdPezNqdCpsHnHibjs7Lc9Mjl5HO/b4TFBVdVX05yTHdfsc7yOyd5T3ffaraVMQvjb0uf1N2vW2f5g5O8pLu/c7aVMU0+9zAZn5XlpkcuJ5/7feMw1MX3gSSP28PyXx3PYTHdJsmH9rD8iiT/eUa1MDs+9zAZn5XlpkcuJ5/7fWDP4oKrqvsm+Zskn0xyUb7xEIvtSb4zyQnd/Y7NqZBpqqq3JrkmyaO7+8ZVyw5Jcm6So7r7uJkXx9T43MNkfFaWmx65nHzu942wuASq6uiMvkH5r0mOGA9fm9FJ3Gd391WbUxnTVlXfn+SNSW6V5B35xn8Q753RVcC2d7dv0BaMzz1MxmdleemRy8vnfnLCIiy4qrp1kkdm7X8QX9Xd/7ZZtQHAZtIjYc+ERQAAAAZc4GbJVdXLq+pNm10HMDs+9zAZnxVYPj7330hYpOK/g6VVVX9bVR/d7DqYOZ97mIzPyhLTI5eWz/0KDkOFJVZVz01yRHf/0mbXAgAHEj0ShEWAhVRVt8voSm/H5hsv2nBxRld6+8Rm1QYAm0mPnJxdrEuuqrZU1W9vdh1sjqr6rqp62WbXwcaqqh/L6EbTP5/RjYVfNX58YDz2waq61+ZVCPNBj1xueuRi0iP3jT2LS66qfjDJu7v7oM2uhdnz919MVbUjySXd/cR1lp+Z5Nju/uHZVgbzxb+Ry83ffzHpkfvm4M0ugOmqqvvsZcqdZlIIm6KqHrWXKVtnUgizdtckv7CH5X+c5OQZ1QIHLD1yuemRS0uP3AfC4uJ7a5LO6MpO67F7eXGdm+RLWf9v7FD0xXRNknsluWKd5fcaz4Fl99bokcvs3OiRy0iP3AfC4uK7LsmTk/yfdZbfLYl7ySyuTyV5Yne/bq2FVXVMkstmWhGz8MIkZ1fVjyR5Y5Kd4/EtSbYnOSnJaZtSGRxY9MjlpkcuJz1yHwiLi+/dSf5Ld39mrYVV9dns+RtV5ttlSX4oyZqNMHv/Rp051N1nVdVnMvqf4F9Osvt8m5sy+m/iUd396s2qDw4geuRy0yOXkB65b4TFxfcnSf7THpZ/PIn7By2uFyY5dA/LP5Lk+BnVwgx19/lJzq+qWyY5bDx8XXd/dRPLggONHrnc9MglpUdOztVQl9D4csA7uvsrm10LABxI9EiAr3Pi7nJ6Q5Lv3OwiAOAApEcCjAmLy8nx9wCwNj0SYExYBAAAYEBYXE6/mq9fJhgA+Do9EmDMBW4AAAAYsGcRAACAAWERAACAAWERFlBVXVVVT9nsOgDgQKI/wr4RFmEOVdWWqjqzqj5aVV+pqk9W1Ruq6oTNrg0ANov+CBvr4M0uANg3VXV0kouTfD7J05K8L6Mvfn4iydlJtm5acQCwSfRH2Hj2LML8OWv8c1t3v7q7r+juD3X3Hyb5gbVWqKrTq+r9VfXF8besf1pV375i+bdV1Suq6tNVdUNVfayqTlux/Fer6p/Hy66rqgurypdNABxI9EfYYP5jhjlSVd+R5H5Jnt7dX1i9vLv/dZ1Vv5bktCQfS3L7JC8ZP35xvPxZSe6W5Gcyur/YHZIcPn7NbUn+KMmjk/xdkm9P8uMb8HYAYEPojzAdwiLMl+9OUkk+tC8rdfeLVzy9qqp+I8n/W1WP7u6vZdQg393d7xrPuXrF/K1Jvpjk9d39+fGy9+1n/QAwDfojTIHDUGG+1H6tVPXjVfXGqvpEVX0+yeuSHJLkiPGUP05yYlW9r6peWFX3XbH6GzNqgFdW1Sur6tFVdeub8yYAYIPpjzAFwiLMlw8n6STfN+kKVXX7JH+T0betP5/kHkkeM158SJJ09xsy+vb0hUkOS/I3VfVn42WfT/JDSR6a5OMZXTTgn6rqqA14PwCwEfRHmAJhEeZId1+f5MIkv1ZVh65evvKk/BW2ZdT0ntzdl3b3PycZNLLuvq67X9HdJyX55SSPrqpvGi/79+5+c3c/LaOLBPynjM7fAIBNpz/CdDhnEebP4zO6NPiOqvqtJO/P6PCb4zP6VnP1pcE/nNEXQ6dV1euS/NeMTub/D1X1u0neneQDGf278OAkH+vur1TVzyS5Y5K3J7l+/Dq3zj6eFwIAU6Y/wgazZxHmTHd/LKPDXt6Y5HkZNcM3J/nZJCevMf/9SZ6U5PQkH0zy2CRPWTXtK0mendGJ+Rdn1OweMF72r0kemORvk/zTeN3Hdvc7Nu5dAcDNoz/Cxqvu3uwaAAAAOMDYswgAAMCAsAgAAMCAsAgAAMCAsAgAAMCAsAgAAMCAsAgAAMCAsAgAAMCAsAgAAMCAsAgAAMDA/w8AXhLWz/R7UQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax_train, ax_test) = plt.subplots(figsize=(15,10), ncols = 2)\n",
    "df_train_tmp['TREND_MID_PRICE'].value_counts().plot(kind='bar', ax=ax_train, fontsize=14)\n",
    "df_test_tmp['TREND_MID_PRICE'].value_counts().plot(kind='bar', ax=ax_test, fontsize=14)\n",
    "ax_train.set_ylabel('Observation counts', fontsize=14)\n",
    "ax_train.set_xlabel('Class', fontsize=14)\n",
    "ax_test.set_ylabel('Observation counts', fontsize=14)\n",
    "ax_test.set_xlabel('Class', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc42cd",
   "metadata": {},
   "source": [
    "## CNN with LSTM\n",
    "\n",
    "References: \n",
    "\n",
    "[1] Zhang, Z., Zohren, S. and Roberts, S. (2018) DeepLOB: Deep Convolutional Neural Networks for Limit Order Books. \n",
    "<br>\n",
    "[2] Iosifidis, A. et al. (2017) Forecasting Stock Prices from the Limit Order Book using Convolutional Neural Networks. \n",
    "\n",
    "CNN model:\n",
    "https://github.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books\n",
    "\n",
    "### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bbccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = r'/Users/ignacioaranguren/QR_assignment/'\n",
    "os.chdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcd1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the necessary modules to optimize memory usage\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d53d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp = pd.read_csv(f'data/sets/train_set_k_20.csv').set_index('Matching Time')\n",
    "df_test = pd.read_csv(f'data/sets/test_set_k_20.csv').set_index('Matching Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce372428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(data, train_end_index):\n",
    "    tmp = data.reset_index()\n",
    "    train = tmp.iloc[:train_end_index].set_index(['Matching Time'],drop=True)\n",
    "    validation = tmp[train_end_index:].set_index(['Matching Time'],drop=True)\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178cc33",
   "metadata": {},
   "source": [
    "We use a reduced training and tests datasets since the data processing has to be carried out in matrixes of 100 x 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b283b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce the orgininal train set. My computer can't handle the processing with full size\n",
    "df_train_tmp_reduced = df_train_tmp.iloc[:int(len(df_train_tmp)*0.8)]\n",
    "df_test = df_test[:int(len(df_test)*0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e32f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_val_ratio = 0.8\n",
    "train_index = int(len(df_train_tmp_reduced) * train_to_val_ratio)\n",
    "df_train, df_val = train_validation_split(df_train_tmp_reduced, train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab1251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, n_input):\n",
    "    [N, D] = X.shape # returns the dimension of the set. N_Observations x 40 \n",
    "    dataX = np.zeros((N - n_input + 1, n_input, D)) # Create N-H + 1 matrixes of n_input x 40 dimension\n",
    "    for i in tqdm(range(n_input, N + 1)):\n",
    "        dataX[i - n_input] = X[i - n_input:i, :]\n",
    "    return dataX.reshape(dataX.shape + (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2354ce6",
   "metadata": {},
   "source": [
    "The original paper used a depth of 100 in the LOB. Due to limitations in computational power, I am using a depth of 20 in my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cd1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 20\n",
    "\n",
    "def prepare_x_y(data, n_input):\n",
    "    x = np.array(data.iloc[:, 2:-2])\n",
    "    y = data.iloc[:, -1:].values\n",
    "    y = y[n_input -1:]\n",
    "    x = data_classification(x, n_input)\n",
    "    y = to_categorical(y, 3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5941acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2895253/2895253 [00:17<00:00, 161067.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_CNN, y_train_CNN = prepare_x_y(df_train, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9e5d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 723800/723800 [00:03<00:00, 219822.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val_CNN, y_val_CNN = prepare_x_y(df_val, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac65adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1682186/1682186 [00:08<00:00, 204284.85it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_CNN, y_test_CNN = prepare_x_y(df_test, n_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4dce83",
   "metadata": {},
   "source": [
    "We can see the results. This will be the training, val and test sets that will be used to fit, validate and test the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe7fdd",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "We create the model described by Zhang (2018) adapted to peform hyperparameter selection. The hyperparameters to be tested are:\n",
    "\n",
    "- Learning rate: Used in order to control the step's size in gradient descent. \n",
    "- Dropout rate: Parameter used to control overfitting. It randomly drops units in the NN accordingly to the rate specified.\n",
    "- Alpha rate: Avoids \"Dying ReLu\" problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c6bed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D, LeakyReLU, concatenate\n",
    "from keras.models import load_model, Model\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import keras_tuner\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f36a56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_CNN(n_observation, n_predictors, n_layers, dropout_rate, learning_rate, alpha_rate):\n",
    "    input_lmd = Input(shape=(n_observation, n_predictors, 1))\n",
    "    \n",
    "    # Build the convolutional block\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    \n",
    "    # build the inception module\n",
    "    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = LeakyReLU(alpha=alpha_rate)(convsecond_1)\n",
    "    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = LeakyReLU(alpha=alpha_rate)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = LeakyReLU(alpha=alpha_rate)(convsecond_2)\n",
    "    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = LeakyReLU(alpha=alpha_rate)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "    \n",
    "    convsecond_output = concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n",
    "    conv_reshape = Dropout(rate=dropout_rate, noise_shape=(None, 1, int(conv_reshape.shape[2])))(conv_reshape, training=True)\n",
    "\n",
    "    # Build the last LSTM layer\n",
    "    conv_lstm = LSTM(n_layers)(conv_reshape)\n",
    "\n",
    "    # Build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model = Model(inputs=input_lmd, outputs=out)\n",
    "    adam = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "class HyperRegressorCNN(keras_tuner.HyperModel):\n",
    "    def __init__(self, n_layers, n_observation, n_predictors, *args, **kwargs):\n",
    "        # Pass all arguments except number of layers, n_observation and n_predictors to parent\n",
    "        self.n_layers = n_layers\n",
    "        self.n_observation = n_observation\n",
    "        self.n_predictors = n_predictors\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Hyperparameters choices and ranges definition \n",
    "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "        dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, default=0.25, step=0.1)\n",
    "        alpha_rate = hp.Float(\"alpha_rate\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
    "        return keras_model_CNN(\n",
    "            self.n_observation, \n",
    "            self.n_predictors,\n",
    "            self.n_layers,\n",
    "            dropout_rate, \n",
    "            learning_rate, \n",
    "            alpha_rate\n",
    "        )\n",
    "    \n",
    "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
    "        model.fit(x, y, **kwargs)\n",
    "        x_val, y_val = validation_data\n",
    "        y_pred = model.predict(x_val)\n",
    "        # Return a single float to minimize.\n",
    "        return -np.sum(y_val * np.log(y_pred)) # Categorical cross entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f356c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# CONSTANTS DEFINITION #\n",
    "########################\n",
    "\n",
    "MAX_TRIALS = 3\n",
    "EXECUTION_PER_TRIAL = 1\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "n_observation = X_train_CNN.shape[1]\n",
    "n_predictors = X_train_CNN.shape[2]\n",
    "n_layers = 64\n",
    "\n",
    "def tune_model():\n",
    "    # Early stop if loss does not improve after 3 epochs\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "    tuner = RandomSearch(\n",
    "        hypermodel=HyperRegressorCNN(n_layers, n_observation, n_predictors),\n",
    "        max_trials=MAX_TRIALS,\n",
    "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "        overwrite=True,\n",
    "        directory='IA_QR',\n",
    "        project_name='CNN'\n",
    "    )\n",
    "    tuner.search(\n",
    "      X_train_CNN, \n",
    "      y_train_CNN,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=(X_val_CNN, y_val_CNN),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a9e5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [01h 36m 44s]\n",
      "default_objective: 429206.09375\n",
      "\n",
      "Best default_objective So Far: 429206.09375\n",
      "Total elapsed time: 04h 49m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_CNN = tune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "545783b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/cnn/tuner_CNN_k_20.pkl','wb') as f:\n",
    "    pickle.dump(tuner_CNN,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a96d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/cnn/tuner_CNN_k_20.pkl','rb') as f:\n",
    "    tuner_CNN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa181683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.002907250525972576, 'dropout_rate': 0.2, 'alpha_rate': 0.004047281713314244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 22:21:40.456933: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "best_hps_CNN = tuner_CNN.get_best_hyperparameters()[0].values\n",
    "print(best_hps_CNN)\n",
    "CNN_model = keras_model_CNN(n_observation, n_predictors, n_layers, **best_hps_CNN) # Rebuild model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c65e5fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "2828/2828 [==============================] - 1946s 687ms/step - loss: 0.7734 - accuracy: 0.6046 - val_loss: 0.7245 - val_accuracy: 0.6629\n",
      "Epoch 2/12\n",
      "2828/2828 [==============================] - 1936s 685ms/step - loss: 0.5904 - accuracy: 0.7322 - val_loss: 0.6177 - val_accuracy: 0.7226\n",
      "Epoch 3/12\n",
      "2828/2828 [==============================] - 1934s 684ms/step - loss: 0.5622 - accuracy: 0.7470 - val_loss: 0.6024 - val_accuracy: 0.7294\n",
      "Epoch 4/12\n",
      "2828/2828 [==============================] - 1927s 681ms/step - loss: 0.5456 - accuracy: 0.7554 - val_loss: 0.5912 - val_accuracy: 0.7355\n",
      "Epoch 5/12\n",
      "2828/2828 [==============================] - 1931s 683ms/step - loss: 0.5341 - accuracy: 0.7611 - val_loss: 0.5821 - val_accuracy: 0.7409\n",
      "Epoch 6/12\n",
      "2828/2828 [==============================] - 1924s 680ms/step - loss: 0.5267 - accuracy: 0.7646 - val_loss: 0.5733 - val_accuracy: 0.7448\n",
      "Epoch 7/12\n",
      "2828/2828 [==============================] - 1926s 681ms/step - loss: 0.5206 - accuracy: 0.7678 - val_loss: 0.5681 - val_accuracy: 0.7472\n",
      "Epoch 8/12\n",
      "2828/2828 [==============================] - 1927s 681ms/step - loss: 0.5164 - accuracy: 0.7698 - val_loss: 0.5609 - val_accuracy: 0.7508\n",
      "Epoch 9/12\n",
      "2828/2828 [==============================] - 1932s 683ms/step - loss: 0.5121 - accuracy: 0.7719 - val_loss: 0.5594 - val_accuracy: 0.7517\n",
      "Epoch 10/12\n",
      "2828/2828 [==============================] - 1931s 683ms/step - loss: 0.5094 - accuracy: 0.7733 - val_loss: 0.5561 - val_accuracy: 0.7537\n",
      "Epoch 11/12\n",
      "2828/2828 [==============================] - 1932s 683ms/step - loss: 0.5072 - accuracy: 0.7742 - val_loss: 0.5527 - val_accuracy: 0.7552\n",
      "Epoch 12/12\n",
      "2828/2828 [==============================] - 1935s 684ms/step - loss: 0.5058 - accuracy: 0.7749 - val_loss: 0.5540 - val_accuracy: 0.7548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3c84cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "CNN_model.fit(X_train_CNN, y_train_CNN, validation_data=(X_val_CNN, y_val_CNN), \n",
    "            epochs=12, batch_size=1024, verbose=1, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc332d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d7e46b77-9649-4c19-8b5a-0aeee480b67c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d7e46b77-9649-4c19-8b5a-0aeee480b67c/assets\n"
     ]
    }
   ],
   "source": [
    "with open('models/cnn/tuner_CNN_refitted_k_20.pkl','wb') as f:\n",
    "    pickle.dump(CNN_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef93954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52569/52569 [==============================] - 316s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = ['STATIONARY', 'POSITIVE', 'NEGATIVE']\n",
    "y_pred_CNN = CNN_model.predict(X_test_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30740f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7675441360230082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  STATIONARY     0.6562    0.7655    0.7066    332725\n",
      "    POSITIVE     0.7756    0.7948    0.7851    664499\n",
      "    NEGATIVE     0.8291    0.7421    0.7832    684962\n",
      "\n",
      "    accuracy                         0.7675   1682186\n",
      "   macro avg     0.7536    0.7675    0.7583   1682186\n",
      "weighted avg     0.7738    0.7675    0.7688   1682186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(np.argmax(y_test_CNN, axis=1), np.argmax(y_pred_CNN, axis=1)))\n",
    "print(classification_report(np.argmax(y_test_CNN, axis=1), np.argmax(y_pred_CNN, axis=1), digits=4, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cbbdc",
   "metadata": {},
   "source": [
    "That's a huge increase in the performance on the stationary class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
