{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7862a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp = pd.read_csv(f'data/sets/train_set.csv').set_index('Matching Time')\n",
    "df_test = pd.read_csv(f'data/sets/test_set.csv').set_index('Matching Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(data, train_end_index):\n",
    "    tmp = data.reset_index()\n",
    "    train = tmp.iloc[:train_end_index].set_index(['Matching Time'],drop=True)\n",
    "    validation = tmp[train_end_index:].set_index(['Matching Time'],drop=True)\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_val_ratio = 0.8\n",
    "train_index = int(len(df_train_tmp_reduced) * train_to_val_ratio)\n",
    "df_train, df_val = train_validation_split(df_train_tmp_reduced, train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e42d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train)+len(df_val))\n",
    "print(len(df_train_tmp_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9306cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y(df):\n",
    "    X_set = []\n",
    "    y_set = []\n",
    "    predictor_list = []\n",
    "    current_mid_price = 0\n",
    "    for row in tqdm(range(len(df))):\n",
    "        # Partitionate LOB states in chunks of 10\n",
    "        if row % 10 == 0 and row != 0:\n",
    "            X_set.append(np.array(predictor_list))\n",
    "            y_set.append(current_mid_price)\n",
    "            predictor_list = []\n",
    "        predictor_list += list(df.iloc[row, 2:len(df.columns) - 2].values)\n",
    "        current_mid_price = df.iloc[row]['TREND_MID_PRICE']\n",
    "    return np.array(X_set), np.array(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_x_y(df_train)\n",
    "y_train = to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = create_x_y(df_val)\n",
    "y_val = to_categorical(y_val, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = create_x_y(df_test)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(n_layers, units, learning_rate, alpha_rate):\n",
    "    # Model definition separated from tuner in order to achieve modularity \n",
    "    # Build model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(400,)))\n",
    "    # Add layers iteratively and assign a units hyperparam selector\n",
    "    for i in range(n_layers):\n",
    "        model.add(layers.Dense(units=units[0][i], activation=LeakyReLU(alpha=alpha_rate)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(units=3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "class HyperRegressor(keras_tuner.HyperModel):\n",
    "    def __init__(self, n_layers, *args, **kwargs):\n",
    "        # Pass all arguments except number of layers to parent\n",
    "        self.n_layers = n_layers\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Hyperparameters choices and ranges definition \n",
    "        units=[hp.Int(f'units_{i + 1}',min_value=16,max_value=256,step=16) for i in range(self.n_layers)],\n",
    "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "        alpha_rate = hp.Float(\"alpha_rate\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
    "        return keras_model(self.n_layers, units, learning_rate, alpha_rate)\n",
    "    \n",
    "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
    "        model.fit(x, y, **kwargs)\n",
    "        x_val, y_val = validation_data\n",
    "        y_pred = model.predict(x_val)\n",
    "        # Return a single float to minimize.\n",
    "        return -np.sum(y_val * np.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# CONSTANTS DEFINITION #\n",
    "########################\n",
    "\n",
    "MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 3\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def tune_model(n_layers=2):\n",
    "    # Early stop if loss does not improve after 3 epochs\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    tuner = RandomSearch(\n",
    "        hypermodel=HyperRegressor(n_layers),\n",
    "        max_trials=MAX_TRIALS,\n",
    "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "        overwrite=True,\n",
    "        directory='IA_QR',\n",
    "        project_name=f'NN_new_{n_layers}'\n",
    "    )\n",
    "    tuner.search(\n",
    "      X_train, \n",
    "      y_train,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=(X_val, y_val),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "parameters = []\n",
    "tuners = []\n",
    "for n in range(1,5):\n",
    "    tuner = tune_model(n)\n",
    "    parameters.append(tuner.get_best_hyperparameters)\n",
    "    models.append(tuner.get_best_models(1)[0])\n",
    "    tuners.append(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tuners)):\n",
    "    print(tuners[i].get_best_hyperparameters()[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b20b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/models.pkl','wb') as f:\n",
    "    pickle.dump(models,f)\n",
    "with open('data/tuners.pkl','wb') as f:\n",
    "    pickle.dump(tuners,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c420e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_units(buffer_dict):\n",
    "    # Convert units param to a list of units to match processing formatting\n",
    "    units = []\n",
    "    # Check if key is unit, if it is add to list \n",
    "    for key, value  in buffer_dict.values.items():\n",
    "        if 'units' in key:\n",
    "            units += [value]\n",
    "    # Crate new dict with correct format \n",
    "    best_params = {}\n",
    "    best_params['units'] = [units]\n",
    "    best_params['learning_rate'] = buffer_dict['learning_rate']\n",
    "    best_params['alpha_rate'] = buffer_dict['alpha_rate']\n",
    "    return best_params\n",
    "\n",
    "models_refitted = []\n",
    "results = {}\n",
    "for i in range(len(models)):\n",
    "    # Build and refit model with best params\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    best_hps = format_units(tuners[i].get_best_hyperparameters()[0])\n",
    "    n_layers = len(best_hps['units']) # Get num of hidden layers\n",
    "    model = keras_model(n_layers, **best_hps) # Rebuild model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16,verbose=True, callbacks=[callback])\n",
    "    models_refitted.append(model)\n",
    "    # Evaluate train and test \n",
    "    train_result = model.evaluate(X_train, y_train, batch_size=16)\n",
    "    val_result = model.evaluate(X_val, y_val, batch_size=16)\n",
    "    test_result = model.evaluate(X_test, y_test, batch_size=16)\n",
    "    results[f'NN{i + 1}'] = {'train': train_result, 'val': val_result, 'test': test_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94405552",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/models_refitted.pkl','wb') as f:\n",
    "    pickle.dump(models_refitted,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72935b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_y_pred(y_pred):\n",
    "    y_pred = []\n",
    "    for trend in y_pred:\n",
    "        index = np.argmax(trend)\n",
    "        print(index)\n",
    "        if index == 0:\n",
    "            y_pred += [0]\n",
    "        elif index == 1:\n",
    "            y_pred += [-1]\n",
    "        else:\n",
    "            y_pred += [1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79746abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_y_pred(y_pred):\n",
    "    y_pred = []\n",
    "    for trend in y_pred:\n",
    "        index = np.argmax(trend)\n",
    "        print(index)\n",
    "        if index == 0:\n",
    "            y_pred += [0]\n",
    "        elif index == 1:\n",
    "            y_pred += [-1]\n",
    "        else:\n",
    "            y_pred += [1]\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
