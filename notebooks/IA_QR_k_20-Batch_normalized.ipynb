{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8872fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import keras_tuner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e498df4",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c6a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r'/Users/ignacioaranguren/QR_assignment/'\n",
    "os.chdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50e60f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Matching Time', 'Receiving Time', 'Symbol']\n",
    "for i in range(1,11):\n",
    "    columns += [f'BID_PRICE{i}', f'BID_QTY_{i}', f'ASK_PRICE_{i}', f'ASK_QTY_{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "013197c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp = pd.read_csv(f'data/exchange1_20210519.csv', names=columns).set_index('Matching Time').append(pd.read_csv(f'data/exchange1_20210520.csv', names=columns).set_index('Matching Time'))\n",
    "df_test_tmp = pd.read_csv(f'data/exchange1_20210521.csv', names=columns).set_index('Matching Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66efddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp['MID_PRICE'] = (df_train_tmp['BID_PRICE1'] + df_train_tmp['ASK_PRICE_1']) / 2\n",
    "df_test_tmp['MID_PRICE'] = (df_test_tmp['BID_PRICE1'] + df_test_tmp['ASK_PRICE_1']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a14f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_price_trend(df, k, alpha):\n",
    "    # Contiguous mid values may be noisy. We need to smooth them by calculating the mean to infere the price trend\n",
    "    trend = []\n",
    "    for i in tqdm(range(k//2, len(df['MID_PRICE']) - k//2)):\n",
    "        prev_k_mid_prices = df.iloc[i - k//2: i, -1].mean()\n",
    "        next_k_mid_prices = df.iloc[i: i + k//2, -1].mean()\n",
    "        if prev_k_mid_prices < next_k_mid_prices * (1 + alpha):\n",
    "            trend += [1]\n",
    "        elif prev_k_mid_prices > next_k_mid_prices * (1 - alpha):\n",
    "            trend += [-1]\n",
    "        else:\n",
    "            trend += [0]\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dbbb376",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_HORIZON = 20\n",
    "ALPHA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "927a08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4523864/4523864 [20:08<00:00, 3743.10it/s]\n"
     ]
    }
   ],
   "source": [
    "trend_train = mid_price_trend(df_train_tmp, K_HORIZON, ALPHA)\n",
    "df_train_tmp['TREND_MID_PRICE'] = pd.Series(trend_train, index=df_train_tmp.index[K_HORIZON//2:-K_HORIZON//2]) \n",
    "df_train_tmp = df_train_tmp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b906b61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2403150/2403150 [10:55<00:00, 3668.28it/s]\n"
     ]
    }
   ],
   "source": [
    "trend_test = mid_price_trend(df_test_tmp, K_HORIZON, ALPHA)\n",
    "df_test_tmp['TREND_MID_PRICE'] = pd.Series(data=trend_test, index=df_test_tmp.index[K_HORIZON//2:-K_HORIZON//2]) \n",
    "df_test_tmp = df_test_tmp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df5825d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BID_PRICE1</th>\n",
       "      <th>BID_QTY_1</th>\n",
       "      <th>ASK_PRICE_1</th>\n",
       "      <th>ASK_QTY_1</th>\n",
       "      <th>BID_PRICE2</th>\n",
       "      <th>BID_QTY_2</th>\n",
       "      <th>ASK_PRICE_2</th>\n",
       "      <th>ASK_QTY_2</th>\n",
       "      <th>BID_PRICE3</th>\n",
       "      <th>BID_QTY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BID_PRICE9</th>\n",
       "      <th>BID_QTY_9</th>\n",
       "      <th>ASK_PRICE_9</th>\n",
       "      <th>ASK_QTY_9</th>\n",
       "      <th>BID_PRICE10</th>\n",
       "      <th>BID_QTY_10</th>\n",
       "      <th>ASK_PRICE_10</th>\n",
       "      <th>ASK_QTY_10</th>\n",
       "      <th>MID_PRICE</th>\n",
       "      <th>TREND_MID_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "      <td>4.523864e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.963470e+04</td>\n",
       "      <td>1.356158e+00</td>\n",
       "      <td>3.963820e+04</td>\n",
       "      <td>1.235090e+00</td>\n",
       "      <td>3.963142e+04</td>\n",
       "      <td>1.087778e+00</td>\n",
       "      <td>3.964151e+04</td>\n",
       "      <td>9.648139e-01</td>\n",
       "      <td>3.962892e+04</td>\n",
       "      <td>1.131413e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.961742e+04</td>\n",
       "      <td>1.398526e+00</td>\n",
       "      <td>3.965576e+04</td>\n",
       "      <td>1.333236e+00</td>\n",
       "      <td>3.961571e+04</td>\n",
       "      <td>1.453538e+00</td>\n",
       "      <td>3.965749e+04</td>\n",
       "      <td>1.375663e+00</td>\n",
       "      <td>3.963645e+04</td>\n",
       "      <td>-9.600863e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.577665e+03</td>\n",
       "      <td>6.476020e+00</td>\n",
       "      <td>1.575651e+03</td>\n",
       "      <td>6.119528e+00</td>\n",
       "      <td>1.578698e+03</td>\n",
       "      <td>4.793466e+00</td>\n",
       "      <td>1.574545e+03</td>\n",
       "      <td>4.609856e+00</td>\n",
       "      <td>1.579507e+03</td>\n",
       "      <td>4.653702e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.583794e+03</td>\n",
       "      <td>4.713733e+00</td>\n",
       "      <td>1.568959e+03</td>\n",
       "      <td>4.927722e+00</td>\n",
       "      <td>1.584524e+03</td>\n",
       "      <td>4.728163e+00</td>\n",
       "      <td>1.568183e+03</td>\n",
       "      <td>4.891516e+00</td>\n",
       "      <td>1.576654e+03</td>\n",
       "      <td>9.304395e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.910000e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.918900e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.909500e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.921300e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.908600e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.900000e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.936500e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.897800e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.945900e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.914450e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.899000e+04</td>\n",
       "      <td>4.830000e-02</td>\n",
       "      <td>3.899400e+04</td>\n",
       "      <td>4.810000e-02</td>\n",
       "      <td>3.898700e+04</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>3.899700e+04</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>3.898500e+04</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.897400e+04</td>\n",
       "      <td>5.550000e-02</td>\n",
       "      <td>3.901000e+04</td>\n",
       "      <td>5.870000e-02</td>\n",
       "      <td>3.897200e+04</td>\n",
       "      <td>5.680000e-02</td>\n",
       "      <td>3.901200e+04</td>\n",
       "      <td>5.880000e-02</td>\n",
       "      <td>3.899250e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.978500e+04</td>\n",
       "      <td>1.750000e-01</td>\n",
       "      <td>3.978800e+04</td>\n",
       "      <td>1.753000e-01</td>\n",
       "      <td>3.978200e+04</td>\n",
       "      <td>1.270000e-01</td>\n",
       "      <td>3.979100e+04</td>\n",
       "      <td>1.275000e-01</td>\n",
       "      <td>3.978000e+04</td>\n",
       "      <td>1.342000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.976900e+04</td>\n",
       "      <td>2.918000e-01</td>\n",
       "      <td>3.980300e+04</td>\n",
       "      <td>3.100000e-01</td>\n",
       "      <td>3.976800e+04</td>\n",
       "      <td>3.200000e-01</td>\n",
       "      <td>3.980500e+04</td>\n",
       "      <td>3.533000e-01</td>\n",
       "      <td>3.978650e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.048000e+04</td>\n",
       "      <td>5.799000e-01</td>\n",
       "      <td>4.048300e+04</td>\n",
       "      <td>5.736000e-01</td>\n",
       "      <td>4.047700e+04</td>\n",
       "      <td>4.114000e-01</td>\n",
       "      <td>4.048600e+04</td>\n",
       "      <td>4.099000e-01</td>\n",
       "      <td>4.047500e+04</td>\n",
       "      <td>4.903000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.046500e+04</td>\n",
       "      <td>1.024300e+00</td>\n",
       "      <td>4.049800e+04</td>\n",
       "      <td>1.084900e+00</td>\n",
       "      <td>4.046400e+04</td>\n",
       "      <td>1.124000e+00</td>\n",
       "      <td>4.049900e+04</td>\n",
       "      <td>1.200000e+00</td>\n",
       "      <td>4.048150e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.364300e+04</td>\n",
       "      <td>7.938822e+02</td>\n",
       "      <td>4.365000e+04</td>\n",
       "      <td>5.456851e+02</td>\n",
       "      <td>4.364200e+04</td>\n",
       "      <td>7.938773e+02</td>\n",
       "      <td>4.365200e+04</td>\n",
       "      <td>5.456851e+02</td>\n",
       "      <td>4.364000e+04</td>\n",
       "      <td>7.845476e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.362900e+04</td>\n",
       "      <td>8.020410e+02</td>\n",
       "      <td>4.366000e+04</td>\n",
       "      <td>5.466064e+02</td>\n",
       "      <td>4.362600e+04</td>\n",
       "      <td>8.019155e+02</td>\n",
       "      <td>4.366100e+04</td>\n",
       "      <td>5.466064e+02</td>\n",
       "      <td>4.364650e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BID_PRICE1     BID_QTY_1   ASK_PRICE_1     ASK_QTY_1    BID_PRICE2  \\\n",
       "count  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   3.963470e+04  1.356158e+00  3.963820e+04  1.235090e+00  3.963142e+04   \n",
       "std    1.577665e+03  6.476020e+00  1.575651e+03  6.119528e+00  1.578698e+03   \n",
       "min    2.910000e+04  1.000000e-04  2.918900e+04  1.000000e-04  2.909500e+04   \n",
       "25%    3.899000e+04  4.830000e-02  3.899400e+04  4.810000e-02  3.898700e+04   \n",
       "50%    3.978500e+04  1.750000e-01  3.978800e+04  1.753000e-01  3.978200e+04   \n",
       "75%    4.048000e+04  5.799000e-01  4.048300e+04  5.736000e-01  4.047700e+04   \n",
       "max    4.364300e+04  7.938822e+02  4.365000e+04  5.456851e+02  4.364200e+04   \n",
       "\n",
       "          BID_QTY_2   ASK_PRICE_2     ASK_QTY_2    BID_PRICE3     BID_QTY_3  \\\n",
       "count  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   1.087778e+00  3.964151e+04  9.648139e-01  3.962892e+04  1.131413e+00   \n",
       "std    4.793466e+00  1.574545e+03  4.609856e+00  1.579507e+03  4.653702e+00   \n",
       "min    1.000000e-04  2.921300e+04  1.000000e-04  2.908600e+04  1.000000e-04   \n",
       "25%    4.000000e-02  3.899700e+04  4.000000e-02  3.898500e+04  5.000000e-02   \n",
       "50%    1.270000e-01  3.979100e+04  1.275000e-01  3.978000e+04  1.342000e-01   \n",
       "75%    4.114000e-01  4.048600e+04  4.099000e-01  4.047500e+04  4.903000e-01   \n",
       "max    7.938773e+02  4.365200e+04  5.456851e+02  4.364000e+04  7.845476e+02   \n",
       "\n",
       "       ...    BID_PRICE9     BID_QTY_9   ASK_PRICE_9     ASK_QTY_9  \\\n",
       "count  ...  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   ...  3.961742e+04  1.398526e+00  3.965576e+04  1.333236e+00   \n",
       "std    ...  1.583794e+03  4.713733e+00  1.568959e+03  4.927722e+00   \n",
       "min    ...  2.900000e+04  1.000000e-04  2.936500e+04  1.000000e-04   \n",
       "25%    ...  3.897400e+04  5.550000e-02  3.901000e+04  5.870000e-02   \n",
       "50%    ...  3.976900e+04  2.918000e-01  3.980300e+04  3.100000e-01   \n",
       "75%    ...  4.046500e+04  1.024300e+00  4.049800e+04  1.084900e+00   \n",
       "max    ...  4.362900e+04  8.020410e+02  4.366000e+04  5.466064e+02   \n",
       "\n",
       "        BID_PRICE10    BID_QTY_10  ASK_PRICE_10    ASK_QTY_10     MID_PRICE  \\\n",
       "count  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06  4.523864e+06   \n",
       "mean   3.961571e+04  1.453538e+00  3.965749e+04  1.375663e+00  3.963645e+04   \n",
       "std    1.584524e+03  4.728163e+00  1.568183e+03  4.891516e+00  1.576654e+03   \n",
       "min    2.897800e+04  1.000000e-04  2.945900e+04  1.000000e-04  2.914450e+04   \n",
       "25%    3.897200e+04  5.680000e-02  3.901200e+04  5.880000e-02  3.899250e+04   \n",
       "50%    3.976800e+04  3.200000e-01  3.980500e+04  3.533000e-01  3.978650e+04   \n",
       "75%    4.046400e+04  1.124000e+00  4.049900e+04  1.200000e+00  4.048150e+04   \n",
       "max    4.362600e+04  8.019155e+02  4.366100e+04  5.466064e+02  4.364650e+04   \n",
       "\n",
       "       TREND_MID_PRICE  \n",
       "count     4.523864e+06  \n",
       "mean     -9.600863e-03  \n",
       "std       9.304395e-01  \n",
       "min      -1.000000e+00  \n",
       "25%      -1.000000e+00  \n",
       "50%       0.000000e+00  \n",
       "75%       1.000000e+00  \n",
       "max       1.000000e+00  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3e0f128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BID_PRICE1</th>\n",
       "      <th>BID_QTY_1</th>\n",
       "      <th>ASK_PRICE_1</th>\n",
       "      <th>ASK_QTY_1</th>\n",
       "      <th>BID_PRICE2</th>\n",
       "      <th>BID_QTY_2</th>\n",
       "      <th>ASK_PRICE_2</th>\n",
       "      <th>ASK_QTY_2</th>\n",
       "      <th>BID_PRICE3</th>\n",
       "      <th>BID_QTY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BID_PRICE9</th>\n",
       "      <th>BID_QTY_9</th>\n",
       "      <th>ASK_PRICE_9</th>\n",
       "      <th>ASK_QTY_9</th>\n",
       "      <th>BID_PRICE10</th>\n",
       "      <th>BID_QTY_10</th>\n",
       "      <th>ASK_PRICE_10</th>\n",
       "      <th>ASK_QTY_10</th>\n",
       "      <th>MID_PRICE</th>\n",
       "      <th>TREND_MID_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "      <td>2.403150e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.911964e+04</td>\n",
       "      <td>9.925812e-01</td>\n",
       "      <td>3.912242e+04</td>\n",
       "      <td>9.672171e-01</td>\n",
       "      <td>3.911676e+04</td>\n",
       "      <td>6.605518e-01</td>\n",
       "      <td>3.912533e+04</td>\n",
       "      <td>6.149208e-01</td>\n",
       "      <td>3.911458e+04</td>\n",
       "      <td>7.417045e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.910476e+04</td>\n",
       "      <td>1.181195e+00</td>\n",
       "      <td>3.913760e+04</td>\n",
       "      <td>1.051765e+00</td>\n",
       "      <td>3.910333e+04</td>\n",
       "      <td>1.256497e+00</td>\n",
       "      <td>3.913909e+04</td>\n",
       "      <td>1.113652e+00</td>\n",
       "      <td>3.912103e+04</td>\n",
       "      <td>-7.944157e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.025563e+03</td>\n",
       "      <td>4.802817e+00</td>\n",
       "      <td>2.024988e+03</td>\n",
       "      <td>6.709653e+00</td>\n",
       "      <td>2.025811e+03</td>\n",
       "      <td>3.275450e+00</td>\n",
       "      <td>2.024741e+03</td>\n",
       "      <td>4.627409e+00</td>\n",
       "      <td>2.026018e+03</td>\n",
       "      <td>3.489606e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.027051e+03</td>\n",
       "      <td>4.093494e+00</td>\n",
       "      <td>2.023451e+03</td>\n",
       "      <td>4.826758e+00</td>\n",
       "      <td>2.027198e+03</td>\n",
       "      <td>4.199408e+00</td>\n",
       "      <td>2.023295e+03</td>\n",
       "      <td>4.706735e+00</td>\n",
       "      <td>2.025275e+03</td>\n",
       "      <td>9.030111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.350400e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.351800e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.349100e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.352500e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.348400e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.347600e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.354500e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.347200e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.354600e+04</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3.351700e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.706900e+04</td>\n",
       "      <td>6.250000e-02</td>\n",
       "      <td>3.707200e+04</td>\n",
       "      <td>6.020000e-02</td>\n",
       "      <td>3.706600e+04</td>\n",
       "      <td>4.200000e-02</td>\n",
       "      <td>3.707600e+04</td>\n",
       "      <td>4.280000e-02</td>\n",
       "      <td>3.706400e+04</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.705300e+04</td>\n",
       "      <td>5.100000e-02</td>\n",
       "      <td>3.708800e+04</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>3.705200e+04</td>\n",
       "      <td>5.160000e-02</td>\n",
       "      <td>3.709000e+04</td>\n",
       "      <td>5.030000e-02</td>\n",
       "      <td>3.707050e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.991800e+04</td>\n",
       "      <td>2.147000e-01</td>\n",
       "      <td>3.992100e+04</td>\n",
       "      <td>2.017000e-01</td>\n",
       "      <td>3.991600e+04</td>\n",
       "      <td>1.303000e-01</td>\n",
       "      <td>3.992300e+04</td>\n",
       "      <td>1.339000e-01</td>\n",
       "      <td>3.991400e+04</td>\n",
       "      <td>1.365000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.990500e+04</td>\n",
       "      <td>3.210000e-01</td>\n",
       "      <td>3.993500e+04</td>\n",
       "      <td>3.180000e-01</td>\n",
       "      <td>3.990400e+04</td>\n",
       "      <td>3.508000e-01</td>\n",
       "      <td>3.993600e+04</td>\n",
       "      <td>3.430000e-01</td>\n",
       "      <td>3.991950e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.086500e+04</td>\n",
       "      <td>6.661000e-01</td>\n",
       "      <td>4.086700e+04</td>\n",
       "      <td>6.010000e-01</td>\n",
       "      <td>4.086200e+04</td>\n",
       "      <td>3.992000e-01</td>\n",
       "      <td>4.087100e+04</td>\n",
       "      <td>3.813000e-01</td>\n",
       "      <td>4.086000e+04</td>\n",
       "      <td>4.449000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.085200e+04</td>\n",
       "      <td>9.997000e-01</td>\n",
       "      <td>4.088100e+04</td>\n",
       "      <td>9.748000e-01</td>\n",
       "      <td>4.085100e+04</td>\n",
       "      <td>1.037800e+00</td>\n",
       "      <td>4.088300e+04</td>\n",
       "      <td>1.012600e+00</td>\n",
       "      <td>4.086550e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.232200e+04</td>\n",
       "      <td>2.988223e+02</td>\n",
       "      <td>4.233500e+04</td>\n",
       "      <td>3.982194e+02</td>\n",
       "      <td>4.231100e+04</td>\n",
       "      <td>3.293249e+02</td>\n",
       "      <td>4.234800e+04</td>\n",
       "      <td>3.729444e+02</td>\n",
       "      <td>4.230900e+04</td>\n",
       "      <td>3.293249e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.229600e+04</td>\n",
       "      <td>3.298676e+02</td>\n",
       "      <td>4.239700e+04</td>\n",
       "      <td>3.730994e+02</td>\n",
       "      <td>4.229200e+04</td>\n",
       "      <td>3.297231e+02</td>\n",
       "      <td>4.239900e+04</td>\n",
       "      <td>3.729886e+02</td>\n",
       "      <td>4.232850e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BID_PRICE1     BID_QTY_1   ASK_PRICE_1     ASK_QTY_1    BID_PRICE2  \\\n",
       "count  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   3.911964e+04  9.925812e-01  3.912242e+04  9.672171e-01  3.911676e+04   \n",
       "std    2.025563e+03  4.802817e+00  2.024988e+03  6.709653e+00  2.025811e+03   \n",
       "min    3.350400e+04  1.000000e-04  3.351800e+04  1.000000e-04  3.349100e+04   \n",
       "25%    3.706900e+04  6.250000e-02  3.707200e+04  6.020000e-02  3.706600e+04   \n",
       "50%    3.991800e+04  2.147000e-01  3.992100e+04  2.017000e-01  3.991600e+04   \n",
       "75%    4.086500e+04  6.661000e-01  4.086700e+04  6.010000e-01  4.086200e+04   \n",
       "max    4.232200e+04  2.988223e+02  4.233500e+04  3.982194e+02  4.231100e+04   \n",
       "\n",
       "          BID_QTY_2   ASK_PRICE_2     ASK_QTY_2    BID_PRICE3     BID_QTY_3  \\\n",
       "count  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   6.605518e-01  3.912533e+04  6.149208e-01  3.911458e+04  7.417045e-01   \n",
       "std    3.275450e+00  2.024741e+03  4.627409e+00  2.026018e+03  3.489606e+00   \n",
       "min    1.000000e-04  3.352500e+04  1.000000e-04  3.348400e+04  1.000000e-04   \n",
       "25%    4.200000e-02  3.707600e+04  4.280000e-02  3.706400e+04  5.000000e-02   \n",
       "50%    1.303000e-01  3.992300e+04  1.339000e-01  3.991400e+04  1.365000e-01   \n",
       "75%    3.992000e-01  4.087100e+04  3.813000e-01  4.086000e+04  4.449000e-01   \n",
       "max    3.293249e+02  4.234800e+04  3.729444e+02  4.230900e+04  3.293249e+02   \n",
       "\n",
       "       ...    BID_PRICE9     BID_QTY_9   ASK_PRICE_9     ASK_QTY_9  \\\n",
       "count  ...  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   ...  3.910476e+04  1.181195e+00  3.913760e+04  1.051765e+00   \n",
       "std    ...  2.027051e+03  4.093494e+00  2.023451e+03  4.826758e+00   \n",
       "min    ...  3.347600e+04  1.000000e-04  3.354500e+04  1.000000e-04   \n",
       "25%    ...  3.705300e+04  5.100000e-02  3.708800e+04  5.000000e-02   \n",
       "50%    ...  3.990500e+04  3.210000e-01  3.993500e+04  3.180000e-01   \n",
       "75%    ...  4.085200e+04  9.997000e-01  4.088100e+04  9.748000e-01   \n",
       "max    ...  4.229600e+04  3.298676e+02  4.239700e+04  3.730994e+02   \n",
       "\n",
       "        BID_PRICE10    BID_QTY_10  ASK_PRICE_10    ASK_QTY_10     MID_PRICE  \\\n",
       "count  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06  2.403150e+06   \n",
       "mean   3.910333e+04  1.256497e+00  3.913909e+04  1.113652e+00  3.912103e+04   \n",
       "std    2.027198e+03  4.199408e+00  2.023295e+03  4.706735e+00  2.025275e+03   \n",
       "min    3.347200e+04  1.000000e-04  3.354600e+04  1.000000e-04  3.351700e+04   \n",
       "25%    3.705200e+04  5.160000e-02  3.709000e+04  5.030000e-02  3.707050e+04   \n",
       "50%    3.990400e+04  3.508000e-01  3.993600e+04  3.430000e-01  3.991950e+04   \n",
       "75%    4.085100e+04  1.037800e+00  4.088300e+04  1.012600e+00  4.086550e+04   \n",
       "max    4.229200e+04  3.297231e+02  4.239900e+04  3.729886e+02  4.232850e+04   \n",
       "\n",
       "       TREND_MID_PRICE  \n",
       "count     2.403150e+06  \n",
       "mean     -7.944157e-03  \n",
       "std       9.030111e-01  \n",
       "min      -1.000000e+00  \n",
       "25%      -1.000000e+00  \n",
       "50%       0.000000e+00  \n",
       "75%       1.000000e+00  \n",
       "max       1.000000e+00  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "830a05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tmp.to_csv('data/sets/unnormalized/test_set_k_20.csv',columns=list(df_test_tmp.columns.values))\n",
    "df_train_tmp.to_csv('data/sets/unnormalized/train_set_k_20.csv',columns=list(df_train_tmp.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bf9c2",
   "metadata": {},
   "source": [
    "## Set balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd61b4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax_train, ax_test) = plt.subplots(figsize=(15,10), ncols = 2)\n",
    "df_train_tmp['TREND_MID_PRICE'].value_counts().plot(kind='bar', ax=ax_train, fontsize=14)\n",
    "df_test_tmp['TREND_MID_PRICE'].value_counts().plot(kind='bar', ax=ax_test, fontsize=14)\n",
    "ax_train.set_ylabel('Observation counts', fontsize=14)\n",
    "ax_train.set_xlabel('Class', fontsize=14)\n",
    "ax_test.set_ylabel('Observation counts', fontsize=14)\n",
    "ax_test.set_xlabel('Class', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc42cd",
   "metadata": {},
   "source": [
    "## CNN with LSTM\n",
    "\n",
    "References: \n",
    "\n",
    "[1] Zhang, Z., Zohren, S. and Roberts, S. (2018) DeepLOB: Deep Convolutional Neural Networks for Limit Order Books. \n",
    "<br>\n",
    "[2] Iosifidis, A. et al. (2017) Forecasting Stock Prices from the Limit Order Book using Convolutional Neural Networks. \n",
    "\n",
    "CNN model:\n",
    "https://github.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books\n",
    "\n",
    "### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bbccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = r'/Users/ignacioaranguren/QR_assignment/'\n",
    "os.chdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcd1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the necessary modules to optimize memory usage\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d53d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp = pd.read_csv(f'data/sets/unnormalized/train_set_k_20.csv').set_index('Matching Time')\n",
    "df_test = pd.read_csv(f'data/sets/unnormalized/test_set_k_20.csv').set_index('Matching Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce372428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(data, train_end_index):\n",
    "    tmp = data.reset_index()\n",
    "    train = tmp.iloc[:train_end_index].set_index(['Matching Time'],drop=True)\n",
    "    validation = tmp[train_end_index:].set_index(['Matching Time'],drop=True)\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178cc33",
   "metadata": {},
   "source": [
    "We use a reduced training and tests datasets since the data processing has to be carried out in matrixes of 100 x 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b283b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reduce the orgininal train set. My computer can't handle the processing with full size\n",
    "df_train_tmp_reduced = df_train_tmp.iloc[:int(len(df_train_tmp)*0.8)]\n",
    "df_test = df_test[:int(len(df_test)*0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e32f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_val_ratio = 0.8\n",
    "train_index = int(len(df_train_tmp_reduced) * train_to_val_ratio)\n",
    "df_train, df_val = train_validation_split(df_train_tmp_reduced, train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d22f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Receiving Time</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>BID_PRICE1</th>\n",
       "      <th>BID_QTY_1</th>\n",
       "      <th>ASK_PRICE_1</th>\n",
       "      <th>ASK_QTY_1</th>\n",
       "      <th>BID_PRICE2</th>\n",
       "      <th>BID_QTY_2</th>\n",
       "      <th>ASK_PRICE_2</th>\n",
       "      <th>ASK_QTY_2</th>\n",
       "      <th>...</th>\n",
       "      <th>BID_PRICE9</th>\n",
       "      <th>BID_QTY_9</th>\n",
       "      <th>ASK_PRICE_9</th>\n",
       "      <th>ASK_QTY_9</th>\n",
       "      <th>BID_PRICE10</th>\n",
       "      <th>BID_QTY_10</th>\n",
       "      <th>ASK_PRICE_10</th>\n",
       "      <th>ASK_QTY_10</th>\n",
       "      <th>MID_PRICE</th>\n",
       "      <th>TREND_MID_PRICE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matching Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.129Z</th>\n",
       "      <td>2021-05-21T00:05:02.137Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>2.6455</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40915.0</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>40875.0</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.160Z</th>\n",
       "      <td>2021-05-21T00:05:02.175Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>2.6894</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40915.0</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>40875.0</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.245Z</th>\n",
       "      <td>2021-05-21T00:05:02.255Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40915.0</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.269Z</th>\n",
       "      <td>2021-05-21T00:05:02.278Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.317Z</th>\n",
       "      <td>2021-05-21T00:05:02.322Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.342Z</th>\n",
       "      <td>2021-05-21T00:05:02.353Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40879.0</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.370Z</th>\n",
       "      <td>2021-05-21T00:05:02.376Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40875.0</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.392Z</th>\n",
       "      <td>2021-05-21T00:05:02.400Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40895.0</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.418Z</th>\n",
       "      <td>2021-05-21T00:05:02.441Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40895.0</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.442Z</th>\n",
       "      <td>2021-05-21T00:05:02.450Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40895.0</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40875.0</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.468Z</th>\n",
       "      <td>2021-05-21T00:05:02.473Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40895.0</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.492Z</th>\n",
       "      <td>2021-05-21T00:05:02.497Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>40895.0</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40916.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.542Z</th>\n",
       "      <td>2021-05-21T00:05:02.555Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>40895.0</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>40901.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>...</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.567Z</th>\n",
       "      <td>2021-05-21T00:05:02.573Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>40901.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>...</td>\n",
       "      <td>40879.0</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>40899.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.592Z</th>\n",
       "      <td>2021-05-21T00:05:02.597Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>40901.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>...</td>\n",
       "      <td>40879.0</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>40917.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40899.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.618Z</th>\n",
       "      <td>2021-05-21T00:05:02.630Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>40906.0</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>...</td>\n",
       "      <td>40879.0</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40878.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>40920.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>40899.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.645Z</th>\n",
       "      <td>2021-05-21T00:05:02.657Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>40906.0</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>...</td>\n",
       "      <td>40879.0</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40920.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>40899.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.668Z</th>\n",
       "      <td>2021-05-21T00:05:02.672Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>40906.0</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>...</td>\n",
       "      <td>40877.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40876.0</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>40920.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>40899.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.697Z</th>\n",
       "      <td>2021-05-21T00:05:02.703Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.3549</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40906.0</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>...</td>\n",
       "      <td>40876.0</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40875.0</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>40920.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.728Z</th>\n",
       "      <td>2021-05-21T00:05:02.735Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40898.0</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>...</td>\n",
       "      <td>40874.0</td>\n",
       "      <td>1.1959</td>\n",
       "      <td>40920.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>40873.0</td>\n",
       "      <td>2.1058</td>\n",
       "      <td>40921.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>40898.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21T00:05:02.797Z</th>\n",
       "      <td>2021-05-21T00:05:02.813Z</td>\n",
       "      <td>BTC-PERP</td>\n",
       "      <td>40894.0</td>\n",
       "      <td>3.8477</td>\n",
       "      <td>40899.0</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>40889.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>...</td>\n",
       "      <td>40873.0</td>\n",
       "      <td>2.1058</td>\n",
       "      <td>40918.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>40871.0</td>\n",
       "      <td>0.6086</td>\n",
       "      <td>40920.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>40896.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Receiving Time    Symbol  BID_PRICE1  \\\n",
       "Matching Time                                                              \n",
       "2021-05-21T00:05:02.129Z  2021-05-21T00:05:02.137Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.160Z  2021-05-21T00:05:02.175Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.245Z  2021-05-21T00:05:02.255Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.269Z  2021-05-21T00:05:02.278Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.317Z  2021-05-21T00:05:02.322Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.342Z  2021-05-21T00:05:02.353Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.370Z  2021-05-21T00:05:02.376Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.392Z  2021-05-21T00:05:02.400Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.418Z  2021-05-21T00:05:02.441Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.442Z  2021-05-21T00:05:02.450Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.468Z  2021-05-21T00:05:02.473Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.492Z  2021-05-21T00:05:02.497Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.542Z  2021-05-21T00:05:02.555Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.567Z  2021-05-21T00:05:02.573Z  BTC-PERP     40899.0   \n",
       "2021-05-21T00:05:02.592Z  2021-05-21T00:05:02.597Z  BTC-PERP     40899.0   \n",
       "2021-05-21T00:05:02.618Z  2021-05-21T00:05:02.630Z  BTC-PERP     40899.0   \n",
       "2021-05-21T00:05:02.645Z  2021-05-21T00:05:02.657Z  BTC-PERP     40899.0   \n",
       "2021-05-21T00:05:02.668Z  2021-05-21T00:05:02.672Z  BTC-PERP     40899.0   \n",
       "2021-05-21T00:05:02.697Z  2021-05-21T00:05:02.703Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.728Z  2021-05-21T00:05:02.735Z  BTC-PERP     40898.0   \n",
       "2021-05-21T00:05:02.797Z  2021-05-21T00:05:02.813Z  BTC-PERP     40894.0   \n",
       "\n",
       "                          BID_QTY_1  ASK_PRICE_1  ASK_QTY_1  BID_PRICE2  \\\n",
       "Matching Time                                                             \n",
       "2021-05-21T00:05:02.129Z     0.0479      40899.0     2.6455     40894.0   \n",
       "2021-05-21T00:05:02.160Z     0.0479      40899.0     2.6894     40894.0   \n",
       "2021-05-21T00:05:02.245Z     0.0479      40899.0     0.6034     40894.0   \n",
       "2021-05-21T00:05:02.269Z     0.0479      40899.0     0.2013     40894.0   \n",
       "2021-05-21T00:05:02.317Z     0.4503      40899.0     0.2013     40894.0   \n",
       "2021-05-21T00:05:02.342Z     0.4503      40899.0     0.0639     40894.0   \n",
       "2021-05-21T00:05:02.370Z     0.4513      40899.0     0.0639     40894.0   \n",
       "2021-05-21T00:05:02.392Z     0.4513      40899.0     0.0639     40895.0   \n",
       "2021-05-21T00:05:02.418Z     0.0489      40899.0     0.0639     40895.0   \n",
       "2021-05-21T00:05:02.442Z     0.0489      40899.0     0.0639     40895.0   \n",
       "2021-05-21T00:05:02.468Z     0.1261      40899.0     0.0639     40895.0   \n",
       "2021-05-21T00:05:02.492Z     0.1261      40899.0     0.0639     40895.0   \n",
       "2021-05-21T00:05:02.542Z     0.4513      40900.0     0.0549     40895.0   \n",
       "2021-05-21T00:05:02.567Z     0.2729      40900.0     0.0549     40898.0   \n",
       "2021-05-21T00:05:02.592Z     0.2729      40900.0     0.0549     40898.0   \n",
       "2021-05-21T00:05:02.618Z     0.6753      40900.0     0.0549     40898.0   \n",
       "2021-05-21T00:05:02.645Z     0.2729      40900.0     0.0549     40898.0   \n",
       "2021-05-21T00:05:02.668Z     0.2729      40900.0     0.0549     40898.0   \n",
       "2021-05-21T00:05:02.697Z     0.1704      40900.0     0.3549     40894.0   \n",
       "2021-05-21T00:05:02.728Z     0.1694      40899.0     0.3855     40894.0   \n",
       "2021-05-21T00:05:02.797Z     3.8477      40899.0     0.8625     40889.0   \n",
       "\n",
       "                          BID_QTY_2  ASK_PRICE_2  ASK_QTY_2  ...  BID_PRICE9  \\\n",
       "Matching Time                                                ...               \n",
       "2021-05-21T00:05:02.129Z     3.8477      40900.0     0.0549  ...     40877.0   \n",
       "2021-05-21T00:05:02.160Z     3.8477      40900.0     0.0549  ...     40877.0   \n",
       "2021-05-21T00:05:02.245Z     3.8477      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.269Z     3.8477      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.317Z     3.8477      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.342Z     3.8477      40900.0     0.0549  ...     40879.0   \n",
       "2021-05-21T00:05:02.370Z     3.8477      40900.0     0.0549  ...     40877.0   \n",
       "2021-05-21T00:05:02.392Z     0.0665      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.418Z     0.0665      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.442Z     0.0665      40900.0     0.0549  ...     40877.0   \n",
       "2021-05-21T00:05:02.468Z     0.0665      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.492Z     0.0665      40900.0     0.0549  ...     40878.0   \n",
       "2021-05-21T00:05:02.542Z     0.0665      40901.0     0.3000  ...     40878.0   \n",
       "2021-05-21T00:05:02.567Z     0.0489      40901.0     0.3000  ...     40879.0   \n",
       "2021-05-21T00:05:02.592Z     0.0489      40901.0     0.3000  ...     40879.0   \n",
       "2021-05-21T00:05:02.618Z     0.0489      40906.0     0.1223  ...     40879.0   \n",
       "2021-05-21T00:05:02.645Z     0.2173      40906.0     0.1223  ...     40879.0   \n",
       "2021-05-21T00:05:02.668Z     0.2173      40906.0     0.1223  ...     40877.0   \n",
       "2021-05-21T00:05:02.697Z     3.8477      40906.0     0.1223  ...     40876.0   \n",
       "2021-05-21T00:05:02.728Z     3.8477      40900.0     0.4949  ...     40874.0   \n",
       "2021-05-21T00:05:02.797Z     0.0100      40900.0     2.7094  ...     40873.0   \n",
       "\n",
       "                          BID_QTY_9  ASK_PRICE_9  ASK_QTY_9  BID_PRICE10  \\\n",
       "Matching Time                                                              \n",
       "2021-05-21T00:05:02.129Z     0.0030      40915.0     0.0132      40875.0   \n",
       "2021-05-21T00:05:02.160Z     0.0030      40915.0     0.0132      40875.0   \n",
       "2021-05-21T00:05:02.245Z     0.5000      40915.0     0.0132      40877.0   \n",
       "2021-05-21T00:05:02.269Z     0.5000      40917.0     0.0258      40877.0   \n",
       "2021-05-21T00:05:02.317Z     0.5000      40917.0     0.0258      40877.0   \n",
       "2021-05-21T00:05:02.342Z     0.0242      40917.0     0.0258      40878.0   \n",
       "2021-05-21T00:05:02.370Z     0.0030      40916.0     0.5000      40875.0   \n",
       "2021-05-21T00:05:02.392Z     0.5000      40916.0     0.5000      40877.0   \n",
       "2021-05-21T00:05:02.418Z     0.5000      40916.0     0.5000      40877.0   \n",
       "2021-05-21T00:05:02.442Z     0.0030      40916.0     0.5000      40875.0   \n",
       "2021-05-21T00:05:02.468Z     0.5000      40916.0     0.5000      40877.0   \n",
       "2021-05-21T00:05:02.492Z     0.5000      40916.0     0.5000      40877.0   \n",
       "2021-05-21T00:05:02.542Z     0.5000      40917.0     0.0258      40877.0   \n",
       "2021-05-21T00:05:02.567Z     0.0242      40917.0     0.0258      40878.0   \n",
       "2021-05-21T00:05:02.592Z     0.0242      40917.0     0.0258      40878.0   \n",
       "2021-05-21T00:05:02.618Z     0.0242      40918.0     0.0100      40878.0   \n",
       "2021-05-21T00:05:02.645Z     0.0242      40918.0     0.0100      40877.0   \n",
       "2021-05-21T00:05:02.668Z     0.0030      40918.0     0.0100      40876.0   \n",
       "2021-05-21T00:05:02.697Z     0.8693      40918.0     0.0100      40875.0   \n",
       "2021-05-21T00:05:02.728Z     1.1959      40920.0     0.0080      40873.0   \n",
       "2021-05-21T00:05:02.797Z     2.1058      40918.0     0.0100      40871.0   \n",
       "\n",
       "                          BID_QTY_10  ASK_PRICE_10  ASK_QTY_10  MID_PRICE  \\\n",
       "Matching Time                                                               \n",
       "2021-05-21T00:05:02.129Z      0.0260       40916.0      0.5000    40898.5   \n",
       "2021-05-21T00:05:02.160Z      0.0260       40916.0      0.5000    40898.5   \n",
       "2021-05-21T00:05:02.245Z      0.0030       40916.0      0.5000    40898.5   \n",
       "2021-05-21T00:05:02.269Z      0.0030       40918.0      0.0170    40898.5   \n",
       "2021-05-21T00:05:02.317Z      0.0030       40918.0      0.0170    40898.5   \n",
       "2021-05-21T00:05:02.342Z      0.5000       40918.0      0.0170    40898.5   \n",
       "2021-05-21T00:05:02.370Z      0.0260       40917.0      0.0258    40898.5   \n",
       "2021-05-21T00:05:02.392Z      0.0030       40917.0      0.0258    40898.5   \n",
       "2021-05-21T00:05:02.418Z      0.0030       40917.0      0.0258    40898.5   \n",
       "2021-05-21T00:05:02.442Z      0.0260       40917.0      0.0258    40898.5   \n",
       "2021-05-21T00:05:02.468Z      0.0030       40917.0      0.0258    40898.5   \n",
       "2021-05-21T00:05:02.492Z      0.0030       40917.0      0.0258    40898.5   \n",
       "2021-05-21T00:05:02.542Z      0.0030       40918.0      0.0170    40899.0   \n",
       "2021-05-21T00:05:02.567Z      0.5000       40918.0      0.0170    40899.5   \n",
       "2021-05-21T00:05:02.592Z      0.5000       40918.0      0.0100    40899.5   \n",
       "2021-05-21T00:05:02.618Z      0.5000       40920.0      0.0080    40899.5   \n",
       "2021-05-21T00:05:02.645Z      0.0030       40920.0      0.0080    40899.5   \n",
       "2021-05-21T00:05:02.668Z      0.8693       40920.0      0.0080    40899.5   \n",
       "2021-05-21T00:05:02.697Z      0.0260       40920.0      0.0080    40899.0   \n",
       "2021-05-21T00:05:02.728Z      2.1058       40921.0      0.1789    40898.5   \n",
       "2021-05-21T00:05:02.797Z      0.6086       40920.0      0.0080    40896.5   \n",
       "\n",
       "                          TREND_MID_PRICE  \n",
       "Matching Time                              \n",
       "2021-05-21T00:05:02.129Z              0.0  \n",
       "2021-05-21T00:05:02.160Z              0.0  \n",
       "2021-05-21T00:05:02.245Z              0.0  \n",
       "2021-05-21T00:05:02.269Z              1.0  \n",
       "2021-05-21T00:05:02.317Z              1.0  \n",
       "2021-05-21T00:05:02.342Z              1.0  \n",
       "2021-05-21T00:05:02.370Z              1.0  \n",
       "2021-05-21T00:05:02.392Z              1.0  \n",
       "2021-05-21T00:05:02.418Z              1.0  \n",
       "2021-05-21T00:05:02.442Z              1.0  \n",
       "2021-05-21T00:05:02.468Z              1.0  \n",
       "2021-05-21T00:05:02.492Z              1.0  \n",
       "2021-05-21T00:05:02.542Z              1.0  \n",
       "2021-05-21T00:05:02.567Z             -1.0  \n",
       "2021-05-21T00:05:02.592Z             -1.0  \n",
       "2021-05-21T00:05:02.618Z             -1.0  \n",
       "2021-05-21T00:05:02.645Z             -1.0  \n",
       "2021-05-21T00:05:02.668Z             -1.0  \n",
       "2021-05-21T00:05:02.697Z             -1.0  \n",
       "2021-05-21T00:05:02.728Z             -1.0  \n",
       "2021-05-21T00:05:02.797Z             -1.0  \n",
       "\n",
       "[21 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[19:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab1251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classification(X, n_input):\n",
    "    [N, D] = X.shape # returns the dimension of the set. N_Observations x 40 \n",
    "    dataX = np.zeros((N - n_input + 1, n_input, D)) # Create N-H + 1 matrixes of n_input x 40 dimension\n",
    "    for i in tqdm(range(n_input, N + 1)):\n",
    "        dataX[i - n_input] = X[i - n_input:i, :]\n",
    "    return dataX.reshape(dataX.shape + (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2354ce6",
   "metadata": {},
   "source": [
    "The original paper used a depth of 100 in the LOB. Due to limitations in computational power, I am using a depth of 20 in my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cd1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 20\n",
    "\n",
    "def prepare_x_y(data, n_input):\n",
    "    x = np.array(data.iloc[:, 2:-2])\n",
    "    y = data.iloc[:, -1:].values\n",
    "    y = y[n_input -1:]\n",
    "    x = data_classification(x, n_input)\n",
    "    y = to_categorical(y, 3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5941acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2895253/2895253 [00:17<00:00, 165048.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_CNN, y_train_CNN = prepare_x_y(df_train, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9e5d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 723800/723800 [00:03<00:00, 183014.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val_CNN, y_val_CNN = prepare_x_y(df_val, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac65adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1682186/1682186 [00:11<00:00, 147683.10it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_CNN, y_test_CNN = prepare_x_y(df_test, n_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe7fdd",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "We create the model described by Zhang (2018) adapted to peform hyperparameter selection. The hyperparameters to be tested are:\n",
    "\n",
    "- Learning rate: Used in order to control the step's size in gradient descent. \n",
    "- Dropout rate: Parameter used to control overfitting. It randomly drops units in the NN accordingly to the rate specified.\n",
    "- Alpha rate: Avoids \"Dying ReLu\" problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c6bed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Flatten, BatchNormalization, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D, LeakyReLU, concatenate\n",
    "from keras.models import load_model, Model\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import keras_tuner\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f36a56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_CNN(n_observation, n_predictors, n_layers, dropout_rate, learning_rate, alpha_rate):\n",
    "    input_lmd = Input(shape=(n_observation, n_predictors, 1))\n",
    "    input_lmd = BatchNormalization()(input_lmd)\n",
    "    # Build the convolutional block\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = LeakyReLU(alpha=alpha_rate)(conv_first1)\n",
    "    \n",
    "    # build the inception module\n",
    "    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = LeakyReLU(alpha=alpha_rate)(convsecond_1)\n",
    "    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = LeakyReLU(alpha=alpha_rate)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = LeakyReLU(alpha=alpha_rate)(convsecond_2)\n",
    "    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = LeakyReLU(alpha=alpha_rate)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "    \n",
    "    convsecond_output = concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n",
    "    conv_reshape = Dropout(rate=dropout_rate, noise_shape=(None, 1, int(conv_reshape.shape[2])))(conv_reshape, training=True)\n",
    "\n",
    "    # Build the last LSTM layer\n",
    "    conv_lstm = LSTM(n_layers)(conv_reshape)\n",
    "\n",
    "    # Build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model = Model(inputs=input_lmd, outputs=out)\n",
    "    adam = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "class HyperRegressorCNN(keras_tuner.HyperModel):\n",
    "    def __init__(self, n_layers, n_observation, n_predictors, *args, **kwargs):\n",
    "        # Pass all arguments except number of layers, n_observation and n_predictors to parent\n",
    "        self.n_layers = n_layers\n",
    "        self.n_observation = n_observation\n",
    "        self.n_predictors = n_predictors\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Hyperparameters choices and ranges definition \n",
    "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "        dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, default=0.25, step=0.1)\n",
    "        alpha_rate = hp.Float(\"alpha_rate\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
    "        return keras_model_CNN(\n",
    "            self.n_observation, \n",
    "            self.n_predictors,\n",
    "            self.n_layers,\n",
    "            dropout_rate, \n",
    "            learning_rate, \n",
    "            alpha_rate\n",
    "        )\n",
    "    \n",
    "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
    "        model.fit(x, y, **kwargs)\n",
    "        x_val, y_val = validation_data\n",
    "        y_pred = model.predict(x_val)\n",
    "        # Return a single float to minimize.\n",
    "        return -np.sum(y_val * np.log(y_pred)) # Categorical cross entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f356c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# CONSTANTS DEFINITION #\n",
    "########################\n",
    "\n",
    "MAX_TRIALS = 3\n",
    "EXECUTION_PER_TRIAL = 1\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "n_observation = X_train_CNN.shape[1]\n",
    "n_predictors = X_train_CNN.shape[2]\n",
    "n_layers = 64\n",
    "\n",
    "def tune_model():\n",
    "    # Early stop if loss does not improve after 3 epochs\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "    tuner = RandomSearch(\n",
    "        hypermodel=HyperRegressorCNN(n_layers, n_observation, n_predictors),\n",
    "        max_trials=MAX_TRIALS,\n",
    "        executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "        overwrite=True,\n",
    "        directory='IA_QR',\n",
    "        project_name='CNN'\n",
    "    )\n",
    "    tuner.search(\n",
    "      X_train_CNN, \n",
    "      y_train_CNN,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=(X_val_CNN, y_val_CNN),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a9e5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [01h 52m 12s]\n",
      "default_objective: 751018.375\n",
      "\n",
      "Best default_objective So Far: 749350.0625\n",
      "Total elapsed time: 03h 42m 39s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.0085686         |0.0085371         |learning_rate\n",
      "0.2               |0.5               |dropout_rate\n",
      "0.00030219        |0.0021501         |alpha_rate\n",
      "\n",
      "Epoch 1/3\n",
      "2828/2828 [==============================] - 1830s 645ms/step - loss: 0.9682 - accuracy: 0.4455\n",
      "Epoch 2/3\n",
      " 773/2828 [=======>......................] - ETA: 21:51 - loss: 0.9669 - accuracy: 0.4455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z6/slbhkttj7gn0pwb0ll_0lfh40000gn/T/ipykernel_69043/966115654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/z6/slbhkttj7gn0pwb0ll_0lfh40000gn/T/ipykernel_69043/2427466075.py\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CNN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0;31m     tuner.search(\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mX_train_CNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0my_train_CNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/z6/slbhkttj7gn0pwb0ll_0lfh40000gn/T/ipykernel_69043/3080696067.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, x, y, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner_CNN = tune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "545783b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/cnn/tuner_CNN_k_20_batch_normalized.pkl','wb') as f:\n",
    "    pickle.dump(tuner_CNN,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a96d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/cnn/tuner_CNN_k_20_batch_normalized.pkl','rb') as f:\n",
    "    tuner_CNN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa181683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.002907250525972576, 'dropout_rate': 0.2, 'alpha_rate': 0.004047281713314244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 15:31:00.315607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "best_hps_CNN = tuner_CNN.get_best_hyperparameters()[0].values\n",
    "print(best_hps_CNN)\n",
    "CNN_model = keras_model_CNN(n_observation, n_predictors, n_layers, **best_hps_CNN) # Rebuild model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65e5fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "2828/2828 [==============================] - 2293s 810ms/step - loss: 0.9674 - accuracy: 0.4453 - val_loss: 1.0374 - val_accuracy: 0.4224\n",
      "Epoch 2/12\n",
      " 754/2828 [======>.......................] - ETA: 27:37 - loss: 0.9667 - accuracy: 0.4450"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z6/slbhkttj7gn0pwb0ll_0lfh40000gn/T/ipykernel_69043/1190179890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m CNN_model.fit(X_train_CNN, y_train_CNN, validation_data=(X_val_CNN, y_val_CNN), \n\u001b[0m\u001b[1;32m      3\u001b[0m             epochs=12, batch_size=1024, verbose=1, callbacks=callback)\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "CNN_model.fit(X_train_CNN, y_train_CNN, validation_data=(X_val_CNN, y_val_CNN), \n",
    "            epochs=12, batch_size=1024, verbose=1, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc332d58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z6/slbhkttj7gn0pwb0ll_0lfh40000gn/T/ipykernel_68439/751236044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/cnn/tuner_CNN_refitted_k_20.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN_model' is not defined"
     ]
    }
   ],
   "source": [
    "with open('models/cnn/CNN_model_refitted_k_20.pkl','wb') as f:\n",
    "    pickle.dump(CNN_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "401d4631",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z6/slbhkttj7gn0pwb0ll_0lfh40000gn/T/ipykernel_68439/725582940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/cnn/tuner_CNN_refitted_k_20.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mCNN_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('models/cnn/tuner_CNN_refitted_k_20.pkl','rb') as f:\n",
    "    CNN_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef93954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52569/52569 [==============================] - 316s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "labels = ['STATIONARY', 'POSITIVE', 'NEGATIVE']\n",
    "y_pred_CNN = CNN_model.predict(X_test_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30740f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7675441360230082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  STATIONARY     0.6562    0.7655    0.7066    332725\n",
      "    POSITIVE     0.7756    0.7948    0.7851    664499\n",
      "    NEGATIVE     0.8291    0.7421    0.7832    684962\n",
      "\n",
      "    accuracy                         0.7675   1682186\n",
      "   macro avg     0.7536    0.7675    0.7583   1682186\n",
      "weighted avg     0.7738    0.7675    0.7688   1682186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(np.argmax(y_test_CNN, axis=1), np.argmax(y_pred_CNN, axis=1)))\n",
    "print(classification_report(np.argmax(y_test_CNN, axis=1), np.argmax(y_pred_CNN, axis=1), digits=4, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cbbdc",
   "metadata": {},
   "source": [
    "That's a huge increase in the performance on the stationary class. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
